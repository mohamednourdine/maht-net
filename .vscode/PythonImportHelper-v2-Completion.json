[
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "torch",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch",
        "description": "torch",
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "nn",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "optim",
        "importPath": "torch",
        "description": "torch",
        "isExtraImport": true,
        "detail": "torch",
        "documentation": {}
    },
    {
        "label": "torch.nn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn",
        "description": "torch.nn",
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "functional",
        "importPath": "torch.nn",
        "description": "torch.nn",
        "isExtraImport": true,
        "detail": "torch.nn",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "TensorDataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "TensorDataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "Dataset",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "DataLoader",
        "importPath": "torch.utils.data",
        "description": "torch.utils.data",
        "isExtraImport": true,
        "detail": "torch.utils.data",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "datasets",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "transforms",
        "importPath": "torchvision",
        "description": "torchvision",
        "isExtraImport": true,
        "detail": "torchvision",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "ndimage",
        "importPath": "scipy",
        "description": "scipy",
        "isExtraImport": true,
        "detail": "scipy",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "seaborn",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "seaborn",
        "description": "seaborn",
        "detail": "seaborn",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "PIL",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "PIL",
        "description": "PIL",
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.common_utils",
        "description": "utilities.common_utils",
        "isExtraImport": true,
        "detail": "utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.common_utils",
        "description": "utilities.common_utils",
        "isExtraImport": true,
        "detail": "utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.common_utils",
        "description": "utilities.common_utils",
        "isExtraImport": true,
        "detail": "utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.common_utils",
        "description": "utilities.common_utils",
        "isExtraImport": true,
        "detail": "utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.plotting",
        "description": "utilities.plotting",
        "isExtraImport": true,
        "detail": "utilities.plotting",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.plotting",
        "description": "utilities.plotting",
        "isExtraImport": true,
        "detail": "utilities.plotting",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.plotting",
        "description": "utilities.plotting",
        "isExtraImport": true,
        "detail": "utilities.plotting",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.plotting",
        "description": "utilities.plotting",
        "isExtraImport": true,
        "detail": "utilities.plotting",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.plotting",
        "description": "utilities.plotting",
        "isExtraImport": true,
        "detail": "utilities.plotting",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.plotting",
        "description": "utilities.plotting",
        "isExtraImport": true,
        "detail": "utilities.plotting",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.plotting",
        "description": "utilities.plotting",
        "isExtraImport": true,
        "detail": "utilities.plotting",
        "documentation": {}
    },
    {
        "label": "UNet",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "UNet",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "UNet",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "UNet",
        "importPath": "model",
        "description": "model",
        "isExtraImport": true,
        "detail": "model",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "io",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "img_as_float",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "io",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "transform",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "img_as_float",
        "importPath": "skimage",
        "description": "skimage",
        "isExtraImport": true,
        "detail": "skimage",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "torchvision.datasets",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torchvision.datasets",
        "description": "torchvision.datasets",
        "detail": "torchvision.datasets",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "isExtraImport": true,
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "ToTensor",
        "importPath": "torchvision.transforms",
        "description": "torchvision.transforms",
        "isExtraImport": true,
        "detail": "torchvision.transforms",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "Variable",
        "importPath": "torch.autograd",
        "description": "torch.autograd",
        "isExtraImport": true,
        "detail": "torch.autograd",
        "documentation": {}
    },
    {
        "label": "torch.nn.functional",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.nn.functional",
        "description": "torch.nn.functional",
        "detail": "torch.nn.functional",
        "documentation": {}
    },
    {
        "label": "make_grid",
        "importPath": "torchvision.utils",
        "description": "torchvision.utils",
        "isExtraImport": true,
        "detail": "torchvision.utils",
        "documentation": {}
    },
    {
        "label": "make_grid",
        "importPath": "torchvision.utils",
        "description": "torchvision.utils",
        "isExtraImport": true,
        "detail": "torchvision.utils",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "matplotlib.patheffects",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.patheffects",
        "description": "matplotlib.patheffects",
        "detail": "matplotlib.patheffects",
        "documentation": {}
    },
    {
        "label": "matplotlib.patches",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.patches",
        "description": "matplotlib.patches",
        "detail": "matplotlib.patches",
        "documentation": {}
    },
    {
        "label": "MaxNLocator",
        "importPath": "matplotlib.ticker",
        "description": "matplotlib.ticker",
        "isExtraImport": true,
        "detail": "matplotlib.ticker",
        "documentation": {}
    },
    {
        "label": "FixedLocator",
        "importPath": "matplotlib.ticker",
        "description": "matplotlib.ticker",
        "isExtraImport": true,
        "detail": "matplotlib.ticker",
        "documentation": {}
    },
    {
        "label": "FormatStrFormatter",
        "importPath": "matplotlib.ticker",
        "description": "matplotlib.ticker",
        "isExtraImport": true,
        "detail": "matplotlib.ticker",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "OrderedDict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.landmark_utils",
        "description": "utilities.landmark_utils",
        "isExtraImport": true,
        "detail": "utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.landmark_utils",
        "description": "utilities.landmark_utils",
        "isExtraImport": true,
        "detail": "utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "utilities.eval_utils",
        "description": "utilities.eval_utils",
        "isExtraImport": true,
        "detail": "utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "zipfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "zipfile",
        "description": "zipfile",
        "detail": "zipfile",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Tuple",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Dict",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "albumentations",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "albumentations",
        "description": "albumentations",
        "detail": "albumentations",
        "documentation": {}
    },
    {
        "label": "ToTensorV2",
        "importPath": "albumentations.pytorch",
        "description": "albumentations.pytorch",
        "isExtraImport": true,
        "detail": "albumentations.pytorch",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "tqdm",
        "importPath": "tqdm",
        "description": "tqdm",
        "isExtraImport": true,
        "detail": "tqdm",
        "documentation": {}
    },
    {
        "label": "timm",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "timm",
        "description": "timm",
        "detail": "timm",
        "documentation": {}
    },
    {
        "label": "rearrange",
        "importPath": "einops",
        "description": "einops",
        "isExtraImport": true,
        "detail": "einops",
        "documentation": {}
    },
    {
        "label": "torch.optim",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "torch.optim",
        "description": "torch.optim",
        "detail": "torch.optim",
        "documentation": {}
    },
    {
        "label": "SummaryWriter",
        "importPath": "torch.utils.tensorboard",
        "description": "torch.utils.tensorboard",
        "isExtraImport": true,
        "detail": "torch.utils.tensorboard",
        "documentation": {}
    },
    {
        "label": "create_maht_net",
        "importPath": "src.models.maht_net",
        "description": "src.models.maht_net",
        "isExtraImport": true,
        "detail": "src.models.maht_net",
        "documentation": {}
    },
    {
        "label": "create_maht_net",
        "importPath": "src.models.maht_net",
        "description": "src.models.maht_net",
        "isExtraImport": true,
        "detail": "src.models.maht_net",
        "documentation": {}
    },
    {
        "label": "create_dataloaders",
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "isExtraImport": true,
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "CephalometricDataset",
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "isExtraImport": true,
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "create_dataloaders",
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "isExtraImport": true,
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "compute_landmark_metrics",
        "importPath": "src.utils.metrics",
        "description": "src.utils.metrics",
        "isExtraImport": true,
        "detail": "src.utils.metrics",
        "documentation": {}
    },
    {
        "label": "compute_clinical_accuracy_metrics",
        "importPath": "src.utils.metrics",
        "description": "src.utils.metrics",
        "isExtraImport": true,
        "detail": "src.utils.metrics",
        "documentation": {}
    },
    {
        "label": "visualize_landmark_errors",
        "importPath": "src.utils.metrics",
        "description": "src.utils.metrics",
        "isExtraImport": true,
        "detail": "src.utils.metrics",
        "documentation": {}
    },
    {
        "label": "create_metrics_report",
        "importPath": "src.utils.metrics",
        "description": "src.utils.metrics",
        "isExtraImport": true,
        "detail": "src.utils.metrics",
        "documentation": {}
    },
    {
        "label": "setup",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "find_packages",
        "importPath": "setuptools",
        "description": "setuptools",
        "isExtraImport": true,
        "detail": "setuptools",
        "documentation": {}
    },
    {
        "label": "MAHTNetTrainer",
        "importPath": "src.training.trainer",
        "description": "src.training.trainer",
        "isExtraImport": true,
        "detail": "src.training.trainer",
        "documentation": {}
    },
    {
        "label": "Point",
        "kind": 6,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "class Point:\n\tdef __init__(self, x, y):\n\t\tself.x = x\n\t\tself.y = y\n\tdef __str__(self):\n\t\treturn str(self.x) + \",\" + str(self.y)\nclass Vector:\n\tdef __init__(self, pa, pb):\n\t\tself.x = int(pb.x) - int(pa.x)\n\t\tself.y = int(pb.y) - int(pa.y)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "Vector",
        "kind": 6,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "class Vector:\n\tdef __init__(self, pa, pb):\n\t\tself.x = int(pb.x) - int(pa.x)\n\t\tself.y = int(pb.y) - int(pa.y)\n\tdef __str__(self):\n\t\treturn str(self.x) + \",\" + str(self.y)\nclass Angle:\n\tdef __init__(self, va, vb):\n\t\tself.va = va\n\t\tself.vb = vb",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "Angle",
        "kind": 6,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "class Angle:\n\tdef __init__(self, va, vb):\n\t\tself.va = va\n\t\tself.vb = vb\n\tdef theta(self):\n\t\ttheta = math.degrees(math.acos(( self.va.x*self.vb.x + self.va.y*self.vb.y ) / (math.hypot(self.va.x, self.va.y)*math.hypot(self.vb.x, self.vb.y))))\n\t\treturn theta\nclass Distance:\n\tdef __init__(self, pa, pb):\n\t\tself.x = (int(pb.x) - int(pa.x))*(int(pb.x) - int(pa.x))",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "Distance",
        "kind": 6,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "class Distance:\n\tdef __init__(self, pa, pb):\n\t\tself.x = (int(pb.x) - int(pa.x))*(int(pb.x) - int(pa.x))\n\t\tself.y = (int(pb.y) - int(pa.y))*(int(pb.y) - int(pa.y))\n\tdef dist(self):\n\t\treturn  (self.x+self.y)**0.5\ndef checkArg():\n\tif len(sys.argv) != 2:\n\t\tprint \"please give me file\"\n\t\tsys.exit(0)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "checkArg",
        "kind": 2,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "def checkArg():\n\tif len(sys.argv) != 2:\n\t\tprint \"please give me file\"\n\t\tsys.exit(0)\ndef readFile(filename):\n\tpoints = []\n\tf = open(filename, \"r\")\n\tfor line in f.readlines():\n\t\tline = line.strip(\" \\t\\n\\r\")\n\t\tx = line.split(\",\")[0]",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "readFile",
        "kind": 2,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "def readFile(filename):\n\tpoints = []\n\tf = open(filename, \"r\")\n\tfor line in f.readlines():\n\t\tline = line.strip(\" \\t\\n\\r\")\n\t\tx = line.split(\",\")[0]\n\t\ty = line.split(\",\")[1]\n\t\tpoints.append(Point(x,y))\n\tf.close()\n\treturn points",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "getCross",
        "kind": 2,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "def getCross(va,vb):\n\treturn va.x*vb.y - va.y*vb.x\ndef getODI(pa,pb,pc,pd,pe,pf,pg,ph):\n\tva = Vector(pa,pb)\n\tvb = Vector(pc,pd)\n\tvc = Vector(pe,pf)\n\tvd = Vector(pg,ph)\n\taa = Angle(va,vb).theta()\n\tab = Angle(vc,vd).theta()\n\tcb = getCross(vc,vd)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "getODI",
        "kind": 2,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "def getODI(pa,pb,pc,pd,pe,pf,pg,ph):\n\tva = Vector(pa,pb)\n\tvb = Vector(pc,pd)\n\tvc = Vector(pe,pf)\n\tvd = Vector(pg,ph)\n\taa = Angle(va,vb).theta()\n\tab = Angle(vc,vd).theta()\n\tcb = getCross(vc,vd)\n\t#print cb\n\tif cb < 0:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "getAPDI",
        "kind": 2,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "def getAPDI(pa,pb,pc,pd,pe,pf,pg,ph,pi,pj):\n\tva = Vector(pa,pb)\n\tvb = Vector(pc,pd)\n\tvc = Vector(pe,pf)\n\tvd = Vector(pg,ph)\n\tve = Vector(pi,pj)\n\t#print vb\n\t#print vc\n\taa = Angle(va,vb).theta()\n\tab = Angle(vb,vc).theta()",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "writeFile",
        "kind": 2,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "def writeFile(filename,points,ANBtype,SNBtype,SNAtype,ODItype,APDItype,FHItype,FMAtype,mwtype):\n\tf = open(filename, \"w\")\n\tfor point in points:\n\t\tf.write(str(point)+ \"\\n\")\n\tf.write(ANBtype + \"\\n\")\n\tf.write(SNBtype + \"\\n\")\n\tf.write(SNAtype + \"\\n\")\n\tf.write(ODItype + \"\\n\")\n\tf.write(APDItype + \"\\n\")\n\tf.write(FHItype + \"\\n\")",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tself.x",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tself.x = x\n\t\tself.y = y\n\tdef __str__(self):\n\t\treturn str(self.x) + \",\" + str(self.y)\nclass Vector:\n\tdef __init__(self, pa, pb):\n\t\tself.x = int(pb.x) - int(pa.x)\n\t\tself.y = int(pb.y) - int(pa.y)\n\tdef __str__(self):\n\t\treturn str(self.x) + \",\" + str(self.y)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tself.y",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tself.y = y\n\tdef __str__(self):\n\t\treturn str(self.x) + \",\" + str(self.y)\nclass Vector:\n\tdef __init__(self, pa, pb):\n\t\tself.x = int(pb.x) - int(pa.x)\n\t\tself.y = int(pb.y) - int(pa.y)\n\tdef __str__(self):\n\t\treturn str(self.x) + \",\" + str(self.y)\nclass Angle:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tself.x",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tself.x = int(pb.x) - int(pa.x)\n\t\tself.y = int(pb.y) - int(pa.y)\n\tdef __str__(self):\n\t\treturn str(self.x) + \",\" + str(self.y)\nclass Angle:\n\tdef __init__(self, va, vb):\n\t\tself.va = va\n\t\tself.vb = vb\n\tdef theta(self):\n\t\ttheta = math.degrees(math.acos(( self.va.x*self.vb.x + self.va.y*self.vb.y ) / (math.hypot(self.va.x, self.va.y)*math.hypot(self.vb.x, self.vb.y))))",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tself.y",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tself.y = int(pb.y) - int(pa.y)\n\tdef __str__(self):\n\t\treturn str(self.x) + \",\" + str(self.y)\nclass Angle:\n\tdef __init__(self, va, vb):\n\t\tself.va = va\n\t\tself.vb = vb\n\tdef theta(self):\n\t\ttheta = math.degrees(math.acos(( self.va.x*self.vb.x + self.va.y*self.vb.y ) / (math.hypot(self.va.x, self.va.y)*math.hypot(self.vb.x, self.vb.y))))\n\t\treturn theta",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tself.va",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tself.va = va\n\t\tself.vb = vb\n\tdef theta(self):\n\t\ttheta = math.degrees(math.acos(( self.va.x*self.vb.x + self.va.y*self.vb.y ) / (math.hypot(self.va.x, self.va.y)*math.hypot(self.vb.x, self.vb.y))))\n\t\treturn theta\nclass Distance:\n\tdef __init__(self, pa, pb):\n\t\tself.x = (int(pb.x) - int(pa.x))*(int(pb.x) - int(pa.x))\n\t\tself.y = (int(pb.y) - int(pa.y))*(int(pb.y) - int(pa.y))\n\tdef dist(self):",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tself.vb",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tself.vb = vb\n\tdef theta(self):\n\t\ttheta = math.degrees(math.acos(( self.va.x*self.vb.x + self.va.y*self.vb.y ) / (math.hypot(self.va.x, self.va.y)*math.hypot(self.vb.x, self.vb.y))))\n\t\treturn theta\nclass Distance:\n\tdef __init__(self, pa, pb):\n\t\tself.x = (int(pb.x) - int(pa.x))*(int(pb.x) - int(pa.x))\n\t\tself.y = (int(pb.y) - int(pa.y))*(int(pb.y) - int(pa.y))\n\tdef dist(self):\n\t\treturn  (self.x+self.y)**0.5",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\ttheta",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\ttheta = math.degrees(math.acos(( self.va.x*self.vb.x + self.va.y*self.vb.y ) / (math.hypot(self.va.x, self.va.y)*math.hypot(self.vb.x, self.vb.y))))\n\t\treturn theta\nclass Distance:\n\tdef __init__(self, pa, pb):\n\t\tself.x = (int(pb.x) - int(pa.x))*(int(pb.x) - int(pa.x))\n\t\tself.y = (int(pb.y) - int(pa.y))*(int(pb.y) - int(pa.y))\n\tdef dist(self):\n\t\treturn  (self.x+self.y)**0.5\ndef checkArg():\n\tif len(sys.argv) != 2:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tself.x",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tself.x = (int(pb.x) - int(pa.x))*(int(pb.x) - int(pa.x))\n\t\tself.y = (int(pb.y) - int(pa.y))*(int(pb.y) - int(pa.y))\n\tdef dist(self):\n\t\treturn  (self.x+self.y)**0.5\ndef checkArg():\n\tif len(sys.argv) != 2:\n\t\tprint \"please give me file\"\n\t\tsys.exit(0)\ndef readFile(filename):\n\tpoints = []",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tself.y",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tself.y = (int(pb.y) - int(pa.y))*(int(pb.y) - int(pa.y))\n\tdef dist(self):\n\t\treturn  (self.x+self.y)**0.5\ndef checkArg():\n\tif len(sys.argv) != 2:\n\t\tprint \"please give me file\"\n\t\tsys.exit(0)\ndef readFile(filename):\n\tpoints = []\n\tf = open(filename, \"r\")",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tpoints",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tpoints = []\n\tf = open(filename, \"r\")\n\tfor line in f.readlines():\n\t\tline = line.strip(\" \\t\\n\\r\")\n\t\tx = line.split(\",\")[0]\n\t\ty = line.split(\",\")[1]\n\t\tpoints.append(Point(x,y))\n\tf.close()\n\treturn points\ndef getCross(va,vb):",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tf",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tf = open(filename, \"r\")\n\tfor line in f.readlines():\n\t\tline = line.strip(\" \\t\\n\\r\")\n\t\tx = line.split(\",\")[0]\n\t\ty = line.split(\",\")[1]\n\t\tpoints.append(Point(x,y))\n\tf.close()\n\treturn points\ndef getCross(va,vb):\n\treturn va.x*vb.y - va.y*vb.x",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tline",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tline = line.strip(\" \\t\\n\\r\")\n\t\tx = line.split(\",\")[0]\n\t\ty = line.split(\",\")[1]\n\t\tpoints.append(Point(x,y))\n\tf.close()\n\treturn points\ndef getCross(va,vb):\n\treturn va.x*vb.y - va.y*vb.x\ndef getODI(pa,pb,pc,pd,pe,pf,pg,ph):\n\tva = Vector(pa,pb)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tx",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tx = line.split(\",\")[0]\n\t\ty = line.split(\",\")[1]\n\t\tpoints.append(Point(x,y))\n\tf.close()\n\treturn points\ndef getCross(va,vb):\n\treturn va.x*vb.y - va.y*vb.x\ndef getODI(pa,pb,pc,pd,pe,pf,pg,ph):\n\tva = Vector(pa,pb)\n\tvb = Vector(pc,pd)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\ty",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\ty = line.split(\",\")[1]\n\t\tpoints.append(Point(x,y))\n\tf.close()\n\treturn points\ndef getCross(va,vb):\n\treturn va.x*vb.y - va.y*vb.x\ndef getODI(pa,pb,pc,pd,pe,pf,pg,ph):\n\tva = Vector(pa,pb)\n\tvb = Vector(pc,pd)\n\tvc = Vector(pe,pf)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tva",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tva = Vector(pa,pb)\n\tvb = Vector(pc,pd)\n\tvc = Vector(pe,pf)\n\tvd = Vector(pg,ph)\n\taa = Angle(va,vb).theta()\n\tab = Angle(vc,vd).theta()\n\tcb = getCross(vc,vd)\n\t#print cb\n\tif cb < 0:\n\t\tab = -ab",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvb",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvb = Vector(pc,pd)\n\tvc = Vector(pe,pf)\n\tvd = Vector(pg,ph)\n\taa = Angle(va,vb).theta()\n\tab = Angle(vc,vd).theta()\n\tcb = getCross(vc,vd)\n\t#print cb\n\tif cb < 0:\n\t\tab = -ab\n\t#print \"u=\" + str(aa)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvc",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvc = Vector(pe,pf)\n\tvd = Vector(pg,ph)\n\taa = Angle(va,vb).theta()\n\tab = Angle(vc,vd).theta()\n\tcb = getCross(vc,vd)\n\t#print cb\n\tif cb < 0:\n\t\tab = -ab\n\t#print \"u=\" + str(aa)\n\t#print \"v=\" + str(ab)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvd",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvd = Vector(pg,ph)\n\taa = Angle(va,vb).theta()\n\tab = Angle(vc,vd).theta()\n\tcb = getCross(vc,vd)\n\t#print cb\n\tif cb < 0:\n\t\tab = -ab\n\t#print \"u=\" + str(aa)\n\t#print \"v=\" + str(ab)\n\treturn aa+ab",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\taa",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\taa = Angle(va,vb).theta()\n\tab = Angle(vc,vd).theta()\n\tcb = getCross(vc,vd)\n\t#print cb\n\tif cb < 0:\n\t\tab = -ab\n\t#print \"u=\" + str(aa)\n\t#print \"v=\" + str(ab)\n\treturn aa+ab\ndef getAPDI(pa,pb,pc,pd,pe,pf,pg,ph,pi,pj):",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tab",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tab = Angle(vc,vd).theta()\n\tcb = getCross(vc,vd)\n\t#print cb\n\tif cb < 0:\n\t\tab = -ab\n\t#print \"u=\" + str(aa)\n\t#print \"v=\" + str(ab)\n\treturn aa+ab\ndef getAPDI(pa,pb,pc,pd,pe,pf,pg,ph,pi,pj):\n\tva = Vector(pa,pb)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tcb",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tcb = getCross(vc,vd)\n\t#print cb\n\tif cb < 0:\n\t\tab = -ab\n\t#print \"u=\" + str(aa)\n\t#print \"v=\" + str(ab)\n\treturn aa+ab\ndef getAPDI(pa,pb,pc,pd,pe,pf,pg,ph,pi,pj):\n\tva = Vector(pa,pb)\n\tvb = Vector(pc,pd)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tab",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tab = -ab\n\t#print \"u=\" + str(aa)\n\t#print \"v=\" + str(ab)\n\treturn aa+ab\ndef getAPDI(pa,pb,pc,pd,pe,pf,pg,ph,pi,pj):\n\tva = Vector(pa,pb)\n\tvb = Vector(pc,pd)\n\tvc = Vector(pe,pf)\n\tvd = Vector(pg,ph)\n\tve = Vector(pi,pj)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tva",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tva = Vector(pa,pb)\n\tvb = Vector(pc,pd)\n\tvc = Vector(pe,pf)\n\tvd = Vector(pg,ph)\n\tve = Vector(pi,pj)\n\t#print vb\n\t#print vc\n\taa = Angle(va,vb).theta()\n\tab = Angle(vb,vc).theta()\n\tac = Angle(vd,ve).theta()",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvb",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvb = Vector(pc,pd)\n\tvc = Vector(pe,pf)\n\tvd = Vector(pg,ph)\n\tve = Vector(pi,pj)\n\t#print vb\n\t#print vc\n\taa = Angle(va,vb).theta()\n\tab = Angle(vb,vc).theta()\n\tac = Angle(vd,ve).theta()\n\tcb = getCross(vb,vc)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvc",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvc = Vector(pe,pf)\n\tvd = Vector(pg,ph)\n\tve = Vector(pi,pj)\n\t#print vb\n\t#print vc\n\taa = Angle(va,vb).theta()\n\tab = Angle(vb,vc).theta()\n\tac = Angle(vd,ve).theta()\n\tcb = getCross(vb,vc)\n\tcc = getCross(vd,ve)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvd",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvd = Vector(pg,ph)\n\tve = Vector(pi,pj)\n\t#print vb\n\t#print vc\n\taa = Angle(va,vb).theta()\n\tab = Angle(vb,vc).theta()\n\tac = Angle(vd,ve).theta()\n\tcb = getCross(vb,vc)\n\tcc = getCross(vd,ve)\n\t#print cb",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tve",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tve = Vector(pi,pj)\n\t#print vb\n\t#print vc\n\taa = Angle(va,vb).theta()\n\tab = Angle(vb,vc).theta()\n\tac = Angle(vd,ve).theta()\n\tcb = getCross(vb,vc)\n\tcc = getCross(vd,ve)\n\t#print cb\n\tif cb > 0:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\taa",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\taa = Angle(va,vb).theta()\n\tab = Angle(vb,vc).theta()\n\tac = Angle(vd,ve).theta()\n\tcb = getCross(vb,vc)\n\tcc = getCross(vd,ve)\n\t#print cb\n\tif cb > 0:\n\t\tab = -ab\n\tif cc < 0:\n\t\tac = -ac",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tab",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tab = Angle(vb,vc).theta()\n\tac = Angle(vd,ve).theta()\n\tcb = getCross(vb,vc)\n\tcc = getCross(vd,ve)\n\t#print cb\n\tif cb > 0:\n\t\tab = -ab\n\tif cc < 0:\n\t\tac = -ac\n\t#print \"p=\" + str(aa)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tac",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tac = Angle(vd,ve).theta()\n\tcb = getCross(vb,vc)\n\tcc = getCross(vd,ve)\n\t#print cb\n\tif cb > 0:\n\t\tab = -ab\n\tif cc < 0:\n\t\tac = -ac\n\t#print \"p=\" + str(aa)\n\t#print \"q=\" + str(ab)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tcb",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tcb = getCross(vb,vc)\n\tcc = getCross(vd,ve)\n\t#print cb\n\tif cb > 0:\n\t\tab = -ab\n\tif cc < 0:\n\t\tac = -ac\n\t#print \"p=\" + str(aa)\n\t#print \"q=\" + str(ab)\n\t#print \"v=\" + str(ac)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tcc",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tcc = getCross(vd,ve)\n\t#print cb\n\tif cb > 0:\n\t\tab = -ab\n\tif cc < 0:\n\t\tac = -ac\n\t#print \"p=\" + str(aa)\n\t#print \"q=\" + str(ab)\n\t#print \"v=\" + str(ac)\n\treturn aa+ab+ac",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tab",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tab = -ab\n\tif cc < 0:\n\t\tac = -ac\n\t#print \"p=\" + str(aa)\n\t#print \"q=\" + str(ab)\n\t#print \"v=\" + str(ac)\n\treturn aa+ab+ac\ndef writeFile(filename,points,ANBtype,SNBtype,SNAtype,ODItype,APDItype,FHItype,FMAtype,mwtype):\n\tf = open(filename, \"w\")\n\tfor point in points:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tac",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tac = -ac\n\t#print \"p=\" + str(aa)\n\t#print \"q=\" + str(ab)\n\t#print \"v=\" + str(ac)\n\treturn aa+ab+ac\ndef writeFile(filename,points,ANBtype,SNBtype,SNAtype,ODItype,APDItype,FHItype,FMAtype,mwtype):\n\tf = open(filename, \"w\")\n\tfor point in points:\n\t\tf.write(str(point)+ \"\\n\")\n\tf.write(ANBtype + \"\\n\")",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tf",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tf = open(filename, \"w\")\n\tfor point in points:\n\t\tf.write(str(point)+ \"\\n\")\n\tf.write(ANBtype + \"\\n\")\n\tf.write(SNBtype + \"\\n\")\n\tf.write(SNAtype + \"\\n\")\n\tf.write(ODItype + \"\\n\")\n\tf.write(APDItype + \"\\n\")\n\tf.write(FHItype + \"\\n\")\n\tf.write(FMAtype + \"\\n\")",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tfilename",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tfilename = str(sys.argv[1])\n\tpoints = readFile(filename)\n\tva = Vector(points[1],points[0])\n\tvb = Vector(points[1],points[5])\n\tvc = Vector(points[1],points[0])\n\tvd = Vector(points[1],points[4])\n\tprint \"1. ANB\" \n\tANBtype = ''\n\tANB = Angle(vc,vd).theta() - Angle(va,vb).theta()\n\tprint ANB",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tpoints",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tpoints = readFile(filename)\n\tva = Vector(points[1],points[0])\n\tvb = Vector(points[1],points[5])\n\tvc = Vector(points[1],points[0])\n\tvd = Vector(points[1],points[4])\n\tprint \"1. ANB\" \n\tANBtype = ''\n\tANB = Angle(vc,vd).theta() - Angle(va,vb).theta()\n\tprint ANB\n\tif ANB < 3.2:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tva",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tva = Vector(points[1],points[0])\n\tvb = Vector(points[1],points[5])\n\tvc = Vector(points[1],points[0])\n\tvd = Vector(points[1],points[4])\n\tprint \"1. ANB\" \n\tANBtype = ''\n\tANB = Angle(vc,vd).theta() - Angle(va,vb).theta()\n\tprint ANB\n\tif ANB < 3.2:\n\t\tANBtype='3'",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvb",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvb = Vector(points[1],points[5])\n\tvc = Vector(points[1],points[0])\n\tvd = Vector(points[1],points[4])\n\tprint \"1. ANB\" \n\tANBtype = ''\n\tANB = Angle(vc,vd).theta() - Angle(va,vb).theta()\n\tprint ANB\n\tif ANB < 3.2:\n\t\tANBtype='3'\n\telif ANB > 5.7:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvc",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvc = Vector(points[1],points[0])\n\tvd = Vector(points[1],points[4])\n\tprint \"1. ANB\" \n\tANBtype = ''\n\tANB = Angle(vc,vd).theta() - Angle(va,vb).theta()\n\tprint ANB\n\tif ANB < 3.2:\n\t\tANBtype='3'\n\telif ANB > 5.7:\n\t\tANBtype='2'",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvd",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvd = Vector(points[1],points[4])\n\tprint \"1. ANB\" \n\tANBtype = ''\n\tANB = Angle(vc,vd).theta() - Angle(va,vb).theta()\n\tprint ANB\n\tif ANB < 3.2:\n\t\tANBtype='3'\n\telif ANB > 5.7:\n\t\tANBtype='2'\n\telse:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tANBtype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tANBtype = ''\n\tANB = Angle(vc,vd).theta() - Angle(va,vb).theta()\n\tprint ANB\n\tif ANB < 3.2:\n\t\tANBtype='3'\n\telif ANB > 5.7:\n\t\tANBtype='2'\n\telse:\n\t\tANBtype='1'\n\tprint ANBtype",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tANB",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tANB = Angle(vc,vd).theta() - Angle(va,vb).theta()\n\tprint ANB\n\tif ANB < 3.2:\n\t\tANBtype='3'\n\telif ANB > 5.7:\n\t\tANBtype='2'\n\telse:\n\t\tANBtype='1'\n\tprint ANBtype\n\tprint",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tva",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tva = Vector(points[1],points[0])\n\tvb = Vector(points[1],points[5])\n\tprint \"2. SNB\"\n\tSNBtype = ''\n\tSNB = Angle(va,vb).theta()\n\tif SNB < 74.6:\n\t\tSNBtype='2'\n\telif SNB > 78.7:\n\t\tSNBtype='3'\n\telse:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvb",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvb = Vector(points[1],points[5])\n\tprint \"2. SNB\"\n\tSNBtype = ''\n\tSNB = Angle(va,vb).theta()\n\tif SNB < 74.6:\n\t\tSNBtype='2'\n\telif SNB > 78.7:\n\t\tSNBtype='3'\n\telse:\n\t\tSNBtype='1'",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tSNBtype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tSNBtype = ''\n\tSNB = Angle(va,vb).theta()\n\tif SNB < 74.6:\n\t\tSNBtype='2'\n\telif SNB > 78.7:\n\t\tSNBtype='3'\n\telse:\n\t\tSNBtype='1'\n\tprint SNB\n\tprint SNBtype",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tSNB",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tSNB = Angle(va,vb).theta()\n\tif SNB < 74.6:\n\t\tSNBtype='2'\n\telif SNB > 78.7:\n\t\tSNBtype='3'\n\telse:\n\t\tSNBtype='1'\n\tprint SNB\n\tprint SNBtype\n\tprint",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tva",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tva = Vector(points[1],points[0])\n\tvb = Vector(points[1],points[4])\n\tprint \"3. SNA\"\n\tSNAtype = ''\n\tSNA = Angle(va,vb).theta()\n\tif SNA < 79.4:\n\t\tSNAtype='3'\n\telif SNA > 83.2:\n\t\tSNAtype='2'\n\telse:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvb",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvb = Vector(points[1],points[4])\n\tprint \"3. SNA\"\n\tSNAtype = ''\n\tSNA = Angle(va,vb).theta()\n\tif SNA < 79.4:\n\t\tSNAtype='3'\n\telif SNA > 83.2:\n\t\tSNAtype='2'\n\telse:\n\t\tSNAtype='1'",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tSNAtype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tSNAtype = ''\n\tSNA = Angle(va,vb).theta()\n\tif SNA < 79.4:\n\t\tSNAtype='3'\n\telif SNA > 83.2:\n\t\tSNAtype='2'\n\telse:\n\t\tSNAtype='1'\n\tprint SNA\n\tprint SNAtype",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tSNA",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tSNA = Angle(va,vb).theta()\n\tif SNA < 79.4:\n\t\tSNAtype='3'\n\telif SNA > 83.2:\n\t\tSNAtype='2'\n\telse:\n\t\tSNAtype='1'\n\tprint SNA\n\tprint SNAtype\n\tprint",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tODItype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tODItype = ''\n\tODI = getODI(points[7],points[9],points[5],points[4],points[3],points[2],points[16],points[17])\n\tif ODI < 68.4:\n\t\tODItype='3'\n\telif ODI > 80.5:\n\t\tODItype='2'\n\telse:\n\t\tODItype='1'\n\tprint ODI\n\tprint ODItype",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tODI",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tODI = getODI(points[7],points[9],points[5],points[4],points[3],points[2],points[16],points[17])\n\tif ODI < 68.4:\n\t\tODItype='3'\n\telif ODI > 80.5:\n\t\tODItype='2'\n\telse:\n\t\tODItype='1'\n\tprint ODI\n\tprint ODItype\n\tprint",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tAPDI",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tAPDI = getAPDI(points[2],points[3],points[1],points[6],points[4],points[5],points[3],points[2],points[16],points[17])\n\tif APDI < 77.6:\n\t\tAPDItype='2'\n\telif APDI > 85.2:\n\t\tAPDItype='3'\n\telse:\n\t\tAPDItype='1'\n\tprint APDI\n\tprint APDItype\n\tprint",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tpfh",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tpfh = Distance(points[0],points[9]).dist()\n\tafh = Distance(points[1],points[7]).dist()\n\tprint \"6. FHI\"\n\tFHItype = ''\n\tprint pfh/afh\n\tif pfh/afh < 0.65:\n\t\tFHItype='3'\n\telif pfh/afh > 0.75:\n\t\tFHItype='2'\n\telse:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tafh",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tafh = Distance(points[1],points[7]).dist()\n\tprint \"6. FHI\"\n\tFHItype = ''\n\tprint pfh/afh\n\tif pfh/afh < 0.65:\n\t\tFHItype='3'\n\telif pfh/afh > 0.75:\n\t\tFHItype='2'\n\telse:\n\t\tFHItype='1'",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tFHItype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tFHItype = ''\n\tprint pfh/afh\n\tif pfh/afh < 0.65:\n\t\tFHItype='3'\n\telif pfh/afh > 0.75:\n\t\tFHItype='2'\n\telse:\n\t\tFHItype='1'\n\tprint FHItype\n\tprint",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tva",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tva = Vector(points[0],points[1])\n\tvb = Vector(points[9],points[8])\n\tprint \"7. FMA\"\n\tFMAtype = ''\n\tif Angle(va,vb).theta() < 26.8:\n\t\tFMAtype='3'\n\telif Angle(va,vb).theta() > 31.4:\n\t\tFMAtype='2'\n\telse:\n\t\tFMAtype='1'",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tvb",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tvb = Vector(points[9],points[8])\n\tprint \"7. FMA\"\n\tFMAtype = ''\n\tif Angle(va,vb).theta() < 26.8:\n\t\tFMAtype='3'\n\telif Angle(va,vb).theta() > 31.4:\n\t\tFMAtype='2'\n\telse:\n\t\tFMAtype='1'\n\tprint Angle(va,vb).theta()",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tFMAtype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tFMAtype = ''\n\tif Angle(va,vb).theta() < 26.8:\n\t\tFMAtype='3'\n\telif Angle(va,vb).theta() > 31.4:\n\t\tFMAtype='2'\n\telse:\n\t\tFMAtype='1'\n\tprint Angle(va,vb).theta()\n\tprint FMAtype\n\tprint",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tmw",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tmw = Distance(points[10],points[11]).dist()/10\n\tmwtype = '';\n\tif points[11].x < points[10].x:\n\t\tmw = -mw\n\tif mw >= 2:\n\t\tif mw <= 4.5:\n\t\t\tmwtype = '1'\n\t\telse:\n\t\t\tmwtype = '4'\n\telif mw == 0:",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\tmwtype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\tmwtype = '';\n\tif points[11].x < points[10].x:\n\t\tmw = -mw\n\tif mw >= 2:\n\t\tif mw <= 4.5:\n\t\t\tmwtype = '1'\n\t\telse:\n\t\t\tmwtype = '4'\n\telif mw == 0:\n\t\tmwtype = '2'",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tmw",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tmw = -mw\n\tif mw >= 2:\n\t\tif mw <= 4.5:\n\t\t\tmwtype = '1'\n\t\telse:\n\t\t\tmwtype = '4'\n\telif mw == 0:\n\t\tmwtype = '2'\n\telse:\n\t\tmwtype = '3'",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\t\tmwtype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\t\tmwtype = '1'\n\t\telse:\n\t\t\tmwtype = '4'\n\telif mw == 0:\n\t\tmwtype = '2'\n\telse:\n\t\tmwtype = '3'\n\tprint \"8. MW\"\n\tprint mw\n\tprint mwtype",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\t\tmwtype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\t\tmwtype = '4'\n\telif mw == 0:\n\t\tmwtype = '2'\n\telse:\n\t\tmwtype = '3'\n\tprint \"8. MW\"\n\tprint mw\n\tprint mwtype\n\t#filename = \"out-\" + filename\n\twriteFile(filename,points,ANBtype,SNBtype,SNAtype,ODItype,APDItype,FHItype,FMAtype,mwtype)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tmwtype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tmwtype = '2'\n\telse:\n\t\tmwtype = '3'\n\tprint \"8. MW\"\n\tprint mw\n\tprint mwtype\n\t#filename = \"out-\" + filename\n\twriteFile(filename,points,ANBtype,SNBtype,SNAtype,ODItype,APDItype,FHItype,FMAtype,mwtype)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t\tmwtype",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t\tmwtype = '3'\n\tprint \"8. MW\"\n\tprint mw\n\tprint mwtype\n\t#filename = \"out-\" + filename\n\twriteFile(filename,points,ANBtype,SNBtype,SNAtype,ODItype,APDItype,FHItype,FMAtype,mwtype)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "\t#filename",
        "kind": 5,
        "importPath": "data.processed.EvaluationCode.angle",
        "description": "data.processed.EvaluationCode.angle",
        "peekOfCode": "\t#filename = \"out-\" + filename\n\twriteFile(filename,points,ANBtype,SNBtype,SNAtype,ODItype,APDItype,FHItype,FMAtype,mwtype)",
        "detail": "data.processed.EvaluationCode.angle",
        "documentation": {}
    },
    {
        "label": "extract_labels_from_txt",
        "kind": 2,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "def extract_labels_from_txt(path):\n    with open(path, \"r\") as f:\n        # only first 19 are actual coords in dataset label files\n        coords_raw = f.readlines()[:19]\n        coords_raw = [tuple([int(float(s)) for s in t.split(\",\")]) for t in coords_raw]\n        return coords_raw\n# In[94]:\ncoords_raw = extract_labels_from_txt(TXT_PATH)\ncoords_raw\n# In[95]:",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "print_image",
        "kind": 2,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "def print_image(img,labels):\n    print(img.shape)\n    plt.rcParams[\"figure.figsize\"] = [32,18]\n    fig = plt.figure()\n    ax1 = fig.add_subplot(2, 2, 1)\n    ax2 = fig.add_subplot(2, 1, 1)\n    ax1.imshow(img, cmap=\"gray\")\n    # also plot resized image for later \n    orig_y, orig_x = img.shape[:2]\n    SCALE = 15",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "display_image_and_cord",
        "kind": 2,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "def display_image_and_cord(image_number,img_path, cord_path):\n    data = []\n    target = []\n    for i, fi in enumerate(os.listdir(img_path)):\n           if i<image_number:\n                loop_img = io.imread(img_path + fi, as_gray=True)\n                lf = fi[:-4] + \".txt\"\n                loop_labels = extract_labels_from_txt(cord_path + lf)\n                loop_labels = (np.array(loop_labels))\n                print(loop_img)",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "SAMPLE_PATH",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "SAMPLE_PATH = \"data/RawImage/Train/TrainingData/005.bmp\"\nTXT_PATH = \"data/AnnotationsByMD/400_senior/005.txt\"\n# import sample image\nimg = io.imread(SAMPLE_PATH, as_gray=True)\nimg\n# In[92]:\nimg.shape\n# In[93]:\n# import sample coordinates from text as tuples\ndef extract_labels_from_txt(path):",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "TXT_PATH",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "TXT_PATH = \"data/AnnotationsByMD/400_senior/005.txt\"\n# import sample image\nimg = io.imread(SAMPLE_PATH, as_gray=True)\nimg\n# In[92]:\nimg.shape\n# In[93]:\n# import sample coordinates from text as tuples\ndef extract_labels_from_txt(path):\n    with open(path, \"r\") as f:",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "img = io.imread(SAMPLE_PATH, as_gray=True)\nimg\n# In[92]:\nimg.shape\n# In[93]:\n# import sample coordinates from text as tuples\ndef extract_labels_from_txt(path):\n    with open(path, \"r\") as f:\n        # only first 19 are actual coords in dataset label files\n        coords_raw = f.readlines()[:19]",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "coords_raw",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "coords_raw = extract_labels_from_txt(TXT_PATH)\ncoords_raw\n# In[95]:\nplt.rcParams[\"figure.figsize\"] = [32,18]\nplt.style.use(['dark_background'])\nfig = plt.figure()\nax1 = fig.add_subplot(2, 2, 1)\nax2 = fig.add_subplot(2, 1, 1)\nax1.imshow(img, cmap=\"gray\")\n# also plot resized image for later ",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "plt.rcParams[\"figure.figsize\"]",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "plt.rcParams[\"figure.figsize\"] = [32,18]\nplt.style.use(['dark_background'])\nfig = plt.figure()\nax1 = fig.add_subplot(2, 2, 1)\nax2 = fig.add_subplot(2, 1, 1)\nax1.imshow(img, cmap=\"gray\")\n# also plot resized image for later \norig_y, orig_x = img.shape[:2]\nSCALE = 15\n# for rescale, use same target for both x&y axis",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "fig",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "fig = plt.figure()\nax1 = fig.add_subplot(2, 2, 1)\nax2 = fig.add_subplot(2, 1, 1)\nax1.imshow(img, cmap=\"gray\")\n# also plot resized image for later \norig_y, orig_x = img.shape[:2]\nSCALE = 15\n# for rescale, use same target for both x&y axis\nrescaled_img = transform.resize(img,(orig_y/SCALE,orig_y/SCALE))\nax2.imshow(rescaled_img, cmap=\"gray\")",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "ax1",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "ax1 = fig.add_subplot(2, 2, 1)\nax2 = fig.add_subplot(2, 1, 1)\nax1.imshow(img, cmap=\"gray\")\n# also plot resized image for later \norig_y, orig_x = img.shape[:2]\nSCALE = 15\n# for rescale, use same target for both x&y axis\nrescaled_img = transform.resize(img,(orig_y/SCALE,orig_y/SCALE))\nax2.imshow(rescaled_img, cmap=\"gray\")\nfor c in coords_raw:",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "ax2",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "ax2 = fig.add_subplot(2, 1, 1)\nax1.imshow(img, cmap=\"gray\")\n# also plot resized image for later \norig_y, orig_x = img.shape[:2]\nSCALE = 15\n# for rescale, use same target for both x&y axis\nrescaled_img = transform.resize(img,(orig_y/SCALE,orig_y/SCALE))\nax2.imshow(rescaled_img, cmap=\"gray\")\nfor c in coords_raw:\n    # add patches to original image",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "SCALE",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "SCALE = 15\n# for rescale, use same target for both x&y axis\nrescaled_img = transform.resize(img,(orig_y/SCALE,orig_y/SCALE))\nax2.imshow(rescaled_img, cmap=\"gray\")\nfor c in coords_raw:\n    # add patches to original image\n    # could also just plt.scatter() but less control then\n    ax1.add_patch(plt.Circle(c, 5, color='r')) \n    # and rescaled marks to resized images\n    x,y = c",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "rescaled_img",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "rescaled_img = transform.resize(img,(orig_y/SCALE,orig_y/SCALE))\nax2.imshow(rescaled_img, cmap=\"gray\")\nfor c in coords_raw:\n    # add patches to original image\n    # could also just plt.scatter() but less control then\n    ax1.add_patch(plt.Circle(c, 5, color='r')) \n    # and rescaled marks to resized images\n    x,y = c\n    x = int(x*(orig_y*1.0/orig_x)/SCALE)\n    y = int(y/SCALE)",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "train_transform",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "train_transform = transforms.Compose([\n        transforms.Resize(224),             # resize shortest side to 224 pixels\n        transforms.CenterCrop(224),         # crop longest side to 224 pixels at center\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ])\ntest_transform = transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "test_transform",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "test_transform = transforms.Compose([\n        transforms.Resize(224),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406],\n                             [0.229, 0.224, 0.225])\n    ])\n# In[100]:\nroot = 'data/RawImage/'\ntrain_data = datasets.ImageFolder(os.path.join(root, 'Train'), transform=train_transform)",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "root",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "root = 'data/RawImage/'\ntrain_data = datasets.ImageFolder(os.path.join(root, 'Train'), transform=train_transform)\ntest_data = datasets.ImageFolder(os.path.join(root, 'Test'), transform=test_transform)\n# In[101]:\ntrain_data\n# In[102]:\ntest_data\n# In[103]:",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "train_data = datasets.ImageFolder(os.path.join(root, 'Train'), transform=train_transform)\ntest_data = datasets.ImageFolder(os.path.join(root, 'Test'), transform=test_transform)\n# In[101]:\ntrain_data\n# In[102]:\ntest_data\n# In[103]:\ntorch.manual_seed(42)",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "test_data",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "test_data = datasets.ImageFolder(os.path.join(root, 'Test'), transform=test_transform)\n# In[101]:\ntrain_data\n# In[102]:\ntest_data\n# In[103]:\ntorch.manual_seed(42)\ntrain_loader = DataLoader(train_data, batch_size=10, shuffle=True)",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "train_loader",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n# In[104]:\nclass_names = test_data.classes\nprint(class_names)\nprint(f'Training images available: {len(train_data)}')\nprint(f'Testing images available:  {len(test_data)}')\n# ## Display a batch of images\n# To verify that the training loader selects cat and dog images at random, let's show a batch of loaded images.<br>\n# Recall that imshow clips pixel values <0, so the resulting display lacks contrast. We'll apply a quick inverse transform to the input tensor so that images show their \"true\" colors.",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "test_loader",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "test_loader = DataLoader(test_data, batch_size=10, shuffle=True)\n# In[104]:\nclass_names = test_data.classes\nprint(class_names)\nprint(f'Training images available: {len(train_data)}')\nprint(f'Testing images available:  {len(test_data)}')\n# ## Display a batch of images\n# To verify that the training loader selects cat and dog images at random, let's show a batch of loaded images.<br>\n# Recall that imshow clips pixel values <0, so the resulting display lacks contrast. We'll apply a quick inverse transform to the input tensor so that images show their \"true\" colors.\n# In[105]:",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "class_names",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "class_names = test_data.classes\nprint(class_names)\nprint(f'Training images available: {len(train_data)}')\nprint(f'Testing images available:  {len(test_data)}')\n# ## Display a batch of images\n# To verify that the training loader selects cat and dog images at random, let's show a batch of loaded images.<br>\n# Recall that imshow clips pixel values <0, so the resulting display lacks contrast. We'll apply a quick inverse transform to the input tensor so that images show their \"true\" colors.\n# In[105]:\n# Grab the first batch of 10 images\nfor images,labels in train_loader: ",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "im",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "im = make_grid(images, nrow=4)  # the default nrow is 8\n# Inverse normalize the images\ninv_normalize = transforms.Normalize(\n    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n    std=[1/0.229, 1/0.224, 1/0.225]\n)\nim_inv = inv_normalize(im)\n# Print the images\nplt.figure(figsize=(32,18))\nplt.imshow(np.transpose(im_inv.numpy(), (1, 2, 0)));",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "inv_normalize",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "inv_normalize = transforms.Normalize(\n    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n    std=[1/0.229, 1/0.224, 1/0.225]\n)\nim_inv = inv_normalize(im)\n# Print the images\nplt.figure(figsize=(32,18))\nplt.imshow(np.transpose(im_inv.numpy(), (1, 2, 0)));",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "im_inv",
        "kind": 5,
        "importPath": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "description": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "peekOfCode": "im_inv = inv_normalize(im)\n# Print the images\nplt.figure(figsize=(32,18))\nplt.imshow(np.transpose(im_inv.numpy(), (1, 2, 0)));",
        "detail": "old-implementation.display the dots annotated.Automated Detection and Analysis for Diagnosis in Cephalometric X-ray Image Using Convolutional Neural Network",
        "documentation": {}
    },
    {
        "label": "DoubleConv",
        "kind": 6,
        "importPath": "old-implementation.model.unet_model",
        "description": "old-implementation.model.unet_model",
        "peekOfCode": "class DoubleConv(nn.Module):\n    def __init__(self, in_ch, out_ch):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1),  #kernel size is 3\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(out_ch),\n            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(out_ch),",
        "detail": "old-implementation.model.unet_model",
        "documentation": {}
    },
    {
        "label": "DownBlock",
        "kind": 6,
        "importPath": "old-implementation.model.unet_model",
        "description": "old-implementation.model.unet_model",
        "peekOfCode": "class DownBlock(nn.Module):\n    def __init__(self, in_ch, out_ch, drop=0):\n        super().__init__()\n        self.mp = nn.MaxPool2d(2)\n        self.drop = nn.Dropout2d(p=drop) if drop is not 0 else None\n        self.conv = DoubleConv(in_ch, out_ch)\n    def forward(self, x):\n        x = self.mp(x)\n        if self.drop is not None:\n            x = self.drop(x)",
        "detail": "old-implementation.model.unet_model",
        "documentation": {}
    },
    {
        "label": "UpBlock",
        "kind": 6,
        "importPath": "old-implementation.model.unet_model",
        "description": "old-implementation.model.unet_model",
        "peekOfCode": "class UpBlock(nn.Module):\n    def __init__(self, in_ch, out_ch, drop=0):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_ch, in_ch // 2, 2, stride=2) #Here to kernel size of 2\n        self.drop = nn.Dropout2d(p=drop) if drop is not 0 else None\n        self.conv = DoubleConv(in_ch, out_ch)\n    def forward(self, x, x_stored):\n        x = self.up(x)\n        x = torch.cat([x, x_stored], dim=1)\n        if self.drop is not None:",
        "detail": "old-implementation.model.unet_model",
        "documentation": {}
    },
    {
        "label": "UNet",
        "kind": 6,
        "importPath": "old-implementation.model.unet_model",
        "description": "old-implementation.model.unet_model",
        "peekOfCode": "class UNet(nn.Module):\n    def __init__(self, in_ch, out_ch, down_drop, up_drop, predict_gaussian=False):\n        super().__init__()\n        assert len(down_drop) == 4\n        assert len(up_drop) == 4\n        self.inconv = DoubleConv(in_ch, 64)\n        self.down1 = DownBlock(64, 128, down_drop[0])\n        self.down2 = DownBlock(128, 256, down_drop[1])\n        self.down3 = DownBlock(256, 512, down_drop[2])\n        self.down4 = DownBlock(512, 1024, down_drop[3])",
        "detail": "old-implementation.model.unet_model",
        "documentation": {}
    },
    {
        "label": "ElasticTransform",
        "kind": 6,
        "importPath": "old-implementation.utilities.common_utils",
        "description": "old-implementation.utilities.common_utils",
        "peekOfCode": "class ElasticTransform():\n    def __init__(self, sigma=8.0, alpha=15.0):\n        self.sigma = sigma\n        self.alpha = alpha\n    def get_coordinates(self, im):\n        dx = np.random.rand(*im.shape) * 2 - 1\n        dy = np.random.rand(*im.shape) * 2 - 1\n        dx = ndimage.gaussian_filter(dx, self.sigma, mode='constant', cval=0) * self.alpha\n        dy = ndimage.gaussian_filter(dy, self.sigma, mode='constant', cval=0) * self.alpha\n        x, y = np.meshgrid(np.arange(im.shape[1]), np.arange(im.shape[0]))",
        "detail": "old-implementation.utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "AffineTransform",
        "kind": 6,
        "importPath": "old-implementation.utilities.common_utils",
        "description": "old-implementation.utilities.common_utils",
        "peekOfCode": "class AffineTransform():\n    def __init__(self, angle, scales=None, tx=None, ty=None):\n        self.scales = scales\n        self.angle = angle\n        self.tx = tx\n        self.ty = ty\n        translations = [tx, ty]\n        for t in translations:\n            if t is not None and not (0.0 <= t <= 1.0):\n                raise ValueError(\"translation values should be between 0 and 1\")",
        "detail": "old-implementation.utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "list_files",
        "kind": 2,
        "importPath": "old-implementation.utilities.common_utils",
        "description": "old-implementation.utilities.common_utils",
        "peekOfCode": "def list_files(dir_path):\n    return sorted(list(dir_path.iterdir()))\n# NRI\ndef get_elastic_transform_coordinates(im, sigma=8.0, alpha=15.0, random_state=None):\n    if random_state is None:\n        random_state = np.random.RandomState(None)\n    dx = random_state.rand(*im.shape) * 2 - 1\n    dy = random_state.rand(*im.shape) * 2 - 1\n    dx = ndimage.gaussian_filter(dx, sigma, mode='constant', cval=0) * alpha\n    dy = ndimage.gaussian_filter(dy, sigma, mode='constant', cval=0) * alpha",
        "detail": "old-implementation.utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "get_elastic_transform_coordinates",
        "kind": 2,
        "importPath": "old-implementation.utilities.common_utils",
        "description": "old-implementation.utilities.common_utils",
        "peekOfCode": "def get_elastic_transform_coordinates(im, sigma=8.0, alpha=15.0, random_state=None):\n    if random_state is None:\n        random_state = np.random.RandomState(None)\n    dx = random_state.rand(*im.shape) * 2 - 1\n    dy = random_state.rand(*im.shape) * 2 - 1\n    dx = ndimage.gaussian_filter(dx, sigma, mode='constant', cval=0) * alpha\n    dy = ndimage.gaussian_filter(dy, sigma, mode='constant', cval=0) * alpha\n    x, y = np.meshgrid(np.arange(im.shape[0]), np.arange(im.shape[1]))\n    coordinates = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1))\n    return coordinates, dx, dy",
        "detail": "old-implementation.utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "count_parameters",
        "kind": 2,
        "importPath": "old-implementation.utilities.common_utils",
        "description": "old-implementation.utilities.common_utils",
        "peekOfCode": "def count_parameters(model):\n    params = [p.numel() for p in model.parameters() if p.requires_grad]\n    print(\"Including the bias terms for each layer, the total number of parameters being trained is:\")\n    for item in params:\n        print(f'{item:>6}')\n    print(f'______\\n{sum(params):>6}')\nclass ElasticTransform():\n    def __init__(self, sigma=8.0, alpha=15.0):\n        self.sigma = sigma\n        self.alpha = alpha",
        "detail": "old-implementation.utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "ORIG_IMAGE_X",
        "kind": 5,
        "importPath": "old-implementation.utilities.common_utils",
        "description": "old-implementation.utilities.common_utils",
        "peekOfCode": "ORIG_IMAGE_X = 1935 \nORIG_IMAGE_Y = 2400\nPIXELS_PER_MM = 10\nN_LANDMARKS = 19\ndef list_files(dir_path):\n    return sorted(list(dir_path.iterdir()))\n# NRI\ndef get_elastic_transform_coordinates(im, sigma=8.0, alpha=15.0, random_state=None):\n    if random_state is None:\n        random_state = np.random.RandomState(None)",
        "detail": "old-implementation.utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "ORIG_IMAGE_Y",
        "kind": 5,
        "importPath": "old-implementation.utilities.common_utils",
        "description": "old-implementation.utilities.common_utils",
        "peekOfCode": "ORIG_IMAGE_Y = 2400\nPIXELS_PER_MM = 10\nN_LANDMARKS = 19\ndef list_files(dir_path):\n    return sorted(list(dir_path.iterdir()))\n# NRI\ndef get_elastic_transform_coordinates(im, sigma=8.0, alpha=15.0, random_state=None):\n    if random_state is None:\n        random_state = np.random.RandomState(None)\n    dx = random_state.rand(*im.shape) * 2 - 1",
        "detail": "old-implementation.utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "PIXELS_PER_MM",
        "kind": 5,
        "importPath": "old-implementation.utilities.common_utils",
        "description": "old-implementation.utilities.common_utils",
        "peekOfCode": "PIXELS_PER_MM = 10\nN_LANDMARKS = 19\ndef list_files(dir_path):\n    return sorted(list(dir_path.iterdir()))\n# NRI\ndef get_elastic_transform_coordinates(im, sigma=8.0, alpha=15.0, random_state=None):\n    if random_state is None:\n        random_state = np.random.RandomState(None)\n    dx = random_state.rand(*im.shape) * 2 - 1\n    dy = random_state.rand(*im.shape) * 2 - 1",
        "detail": "old-implementation.utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "N_LANDMARKS",
        "kind": 5,
        "importPath": "old-implementation.utilities.common_utils",
        "description": "old-implementation.utilities.common_utils",
        "peekOfCode": "N_LANDMARKS = 19\ndef list_files(dir_path):\n    return sorted(list(dir_path.iterdir()))\n# NRI\ndef get_elastic_transform_coordinates(im, sigma=8.0, alpha=15.0, random_state=None):\n    if random_state is None:\n        random_state = np.random.RandomState(None)\n    dx = random_state.rand(*im.shape) * 2 - 1\n    dy = random_state.rand(*im.shape) * 2 - 1\n    dx = ndimage.gaussian_filter(dx, sigma, mode='constant', cval=0) * alpha",
        "detail": "old-implementation.utilities.common_utils",
        "documentation": {}
    },
    {
        "label": "get_true_landmarks",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def get_true_landmarks(annotations_path, image_path):\n    ''' \n    Returns an array of true landmarks for an image, and return an array of the results\n    '''\n    image_id = image_path.stem     #The stem of the filename identified by the path (i.e. the filename without the final extension).\n    annots = (annotations_path / f'{image_id}.txt').read_text()\n    annots = annots.split('\\n')[:N_LANDMARKS]\n    annots = [l.split(',') for l in annots]\n    true_landmarks = [np.array([float(l[1]), float(l[0])]) for l in annots]  # Swap XY to YX order\n    return np.array(true_landmarks)",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "read_prediction_files_as_df",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def read_prediction_files_as_df(prediction_files):\n    ''' \n    Reads individual prediction files as dataframes and then concatenates them into a single dataframe \n    with all predictions for all images and samples.\n    '''\n    dataframes = []\n    for f in prediction_files:\n        dataframes.append(pd.read_csv(f))\n    df = pd.concat(dataframes, ignore_index=True)\n    df.sort_values(FILE_COL, inplace=True)",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "get_predictions_for_image",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def get_predictions_for_image(df, image_file, n_samples):\n    ''' \n    Extracts all of the landmark position and activations samples for the given image from the dataframe\n    and the returns them as numpy arrays.\n    '''\n    image_df = df.loc[df[FILE_COL] == image_file]\n    image_df.reset_index(drop=True, inplace=True)\n    computed_samples = image_df.shape[0]\n    n_samples = min(n_samples, computed_samples)\n    activation_samples = np.zeros((n_samples, N_LANDMARKS))",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "get_landmark_prediction_variance",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def get_landmark_prediction_variance(lm_samples):\n    n_samples, n_landmarks, _ = lm_samples.shape\n    landmark_mean = np.mean(lm_samples, axis=0)\n    distances = np.zeros((n_samples, n_landmarks))\n    for s in range(n_samples):\n        for lm in range(n_landmarks):\n            dist = np.linalg.norm(lm_samples[s, lm] - landmark_mean[lm])\n            distances[s, lm] = dist\n    return np.mean(distances, axis=0)\ndef get_predicted_landmarks_for_image(landmark_samples):",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "get_predicted_landmarks_for_image",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def get_predicted_landmarks_for_image(landmark_samples):\n    ''' \n        Returns the average predicted landmark positions in term of samples and their variance computed\n        as the mean distance between landmarks and the mean landmark.\n        Takes an array of dimension (n_samples, n_landmarks, 2).\n    '''\n    landmark_mean = np.mean(landmark_samples, axis=0)\n    landmark_var = get_landmark_prediction_variance(landmark_samples)\n    return landmark_mean, landmark_var / PIXELS_PER_MM\ndef get_predicted_activations_for_image(activation_samples):",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "get_predicted_activations_for_image",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def get_predicted_activations_for_image(activation_samples):\n    ''' Returns the average activation landmark positions and their variance in term of samples.\n        Takes an array of dimension (n_samples, n_landmarks).\n    '''\n    activation_mean = np.mean(activation_samples, axis=0)\n    activation_var = np.var(activation_samples, axis=0)\n    return activation_mean, activation_var\ndef radial_error_mm(true, pred):\n    ''' \n    Returns the radial error in mms for a single landmark.",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "radial_error_mm",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def radial_error_mm(true, pred):\n    ''' \n    Returns the radial error in mms for a single landmark.\n    The radial error is the distance between the desired point of impact and actual point of impact, \n    both points projected and measured on an imaginary plane drawn perpendicular to the flight path of the munition.\n    '''\n    return np.linalg.norm(pred / PIXELS_PER_MM - true / PIXELS_PER_MM)\ndef get_radial_errors_mm_for_image(true_landmarks, predicted_landmarks):\n    ''' \n        Returns an array containing the radial error for each landmark for the image.",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "get_radial_errors_mm_for_image",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def get_radial_errors_mm_for_image(true_landmarks, predicted_landmarks):\n    ''' \n        Returns an array containing the radial error for each landmark for the image.\n    '''\n    radial_errors = np.zeros(N_LANDMARKS)\n    for lm in range(N_LANDMARKS):\n        radial_errors[lm] = radial_error_mm(true_landmarks[lm], predicted_landmarks[lm])\n    return radial_errors\ndef get_radial_errors_mm_for_individual_landmarks(radial_errors):\n    '''",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "get_radial_errors_mm_for_individual_landmarks",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def get_radial_errors_mm_for_individual_landmarks(radial_errors):\n    '''\n        Returns an array containing the radial error for each landmark for the image.\n    '''\n    print('STATISCAL VALUES ON TEST1')\n    for lm in range(N_LANDMARKS):\n        sdr_lm = np.array([], dtype = np.float32)\n        for errors in np.array(radial_errors):\n            sdr_lm = np.append(sdr_lm, errors[lm])\n        # for result in np.array(lm):",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "get_accuracy_metrics",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def get_accuracy_metrics(radial_errors_mm_all):\n    '''\n    This function Computes the accuracy metrics from radial errors by getting the mean and standard deviation of the\n    results obtaine. This results then compaire to the actial values and printed out.\n    '''\n    # print(f\"Count of the frame { len(radial_errors_mm_all)}\" )\n    mre = radial_errors_mm_all.mean()\n    std = radial_errors_mm_all.std()\n    sdr_2 = (radial_errors_mm_all < 2.0).mean()\n    sdr_2_5 = (radial_errors_mm_all < 2.5).mean()",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "print_accuracy_metrics",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def print_accuracy_metrics(result):\n    '''\n    Success Detection Rate gives the percentage of predictions within that radius of the ground truth.\n    '''\n    print(f\"Mean Root Error (MRE): {result['mre']:{4}.{4}} mm, Standard Deviation (STD): {result['std']:{4}.{4}} mm\\\n           \\nSuccess Detection Rate\\\n           \\nSDR 2mm: {result['sdr_2']:{4}.{4}}\\\n           \\nSDR 2.5mm: {result['sdr_2_5']:{4}.{4}}\\\n           \\nSDR 3mm: {result['sdr_3']:{4}.{4}}\\\n           \\nSDR 4mm: {result['sdr_4']:{4}.{4}}\")",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "log_metrics",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def log_metrics(metrics, metrics_dir, n_samples):\n    ''' \n    Logs the computed metrics to a csv file in the metrics subdirectory of the log directory for the model.\n    '''\n    metrics['samples'] = n_samples\n    metrics_df = pd.DataFrame(data=metrics, index=[0])\n    metrics_df.to_csv(metrics_dir / f'{n_samples}.csv')\ndef get_test_predictions_df(model_log_dir):\n    \"\"\" \n    Load computed model predictions, this function simple reads all the prediction files and return a dataframe of all",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "get_test_predictions_df",
        "kind": 2,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "def get_test_predictions_df(model_log_dir):\n    \"\"\" \n    Load computed model predictions, this function simple reads all the prediction files and return a dataframe of all\n    the predictions files.\n    \"\"\"\n    prediction_dir = model_log_dir / 'predictions'\n    prediction_files = list_files(prediction_dir)\n    predictions_df = read_prediction_files_as_df(prediction_files)\n    return predictions_df",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "FILE_COL",
        "kind": 5,
        "importPath": "old-implementation.utilities.eval_utils",
        "description": "old-implementation.utilities.eval_utils",
        "peekOfCode": "FILE_COL = 'file'\ndef read_prediction_files_as_df(prediction_files):\n    ''' \n    Reads individual prediction files as dataframes and then concatenates them into a single dataframe \n    with all predictions for all images and samples.\n    '''\n    dataframes = []\n    for f in prediction_files:\n        dataframes.append(pd.read_csv(f))\n    df = pd.concat(dataframes, ignore_index=True)",
        "detail": "old-implementation.utilities.eval_utils",
        "documentation": {}
    },
    {
        "label": "ArrayToTensor",
        "kind": 6,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "class ArrayToTensor(object):\n    def __call__(self, np_array):\n        return torch.from_numpy(np_array).float()\nclass LandmarkDataset(Dataset):\n    def __init__(self, image_fnames, annotations_path, gauss_sigma, gauss_amplitude,\n                 elastic_trans=None, affine_trans=None, horizontal_flip=False):\n        self.image_fnames = image_fnames\n        if annotations_path == '': annotations_path = None\n        self.annotations_path = annotations_path\n        self.gauss_sigma = gauss_sigma",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "LandmarkDataset",
        "kind": 6,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "class LandmarkDataset(Dataset):\n    def __init__(self, image_fnames, annotations_path, gauss_sigma, gauss_amplitude,\n                 elastic_trans=None, affine_trans=None, horizontal_flip=False):\n        self.image_fnames = image_fnames\n        if annotations_path == '': annotations_path = None\n        self.annotations_path = annotations_path\n        self.gauss_sigma = gauss_sigma\n        self.gauss_amplitude = gauss_amplitude\n        self.elastic_trans = elastic_trans\n        self.affine_trans = affine_trans",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "get_annots_for_image",
        "kind": 2,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "def get_annots_for_image(annotations_path, image_path, rescaled_image_size=None, orig_image_size=np.array([ORIG_IMAGE_X, ORIG_IMAGE_Y])):\n    '''\n    Gets all the annations of an image and return in a simple array format of [[x1,y1], [x2,y2], ...] \n    '''\n    image_id = image_path.stem\n    annots = (annotations_path / f'{image_id}.txt').read_text()\n    annots = annots.split('\\n')[:N_LANDMARKS]\n    annots = [l.split(',') for l in annots]\n    annots = [(float(l[0]), float(l[1])) for l in annots];\n    annots = np.array(annots)",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "create_true_heatmaps",
        "kind": 2,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "def create_true_heatmaps(annots, image_size, amplitude):\n    heatmaps = np.zeros((annots.shape[0], image_size, image_size))\n    for i, landmark_pos in enumerate(annots):\n        try:\n            x, y = landmark_pos\n            heatmaps[i, y, x] = amplitude  # Swap WxH to HxW\n        except:\n            print(landmark_pos)\n    return heatmaps\ndef reset_heatmap_maximum(heatmap, amplitude):",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "reset_heatmap_maximum",
        "kind": 2,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "def reset_heatmap_maximum(heatmap, amplitude):\n    '''\n    Heatmap maximum value is not equal to the amplitude after the transformation.\n    We zero the heatmap and set it to the amplitude at the new maximum position.\n    '''\n    ind = np.unravel_index(np.argmax(heatmap, axis=None), heatmap.shape)\n    heatmap[:] = 0\n    heatmap[ind] = amplitude\n    return heatmap\nclass ArrayToTensor(object):",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "get_max_yx",
        "kind": 2,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "def get_max_yx(tensor):\n    max_y, argmax_y = tensor.max(dim=0)\n    _, argmax_x = max_y.max(dim=0)\n    max_yx = (argmax_y[argmax_x.item()].item(), argmax_x.item())\n    return np.array(max_yx)\n'''\ndef np_max_yx(arr):\n    argmax_0 = np.argmax(arr, axis=0)\n    max_0 = arr[argmax_0, np.arange(arr.shape[1])]\n    argmax_1 = np.argmax(max_0)",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "np_max_yx",
        "kind": 2,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "def np_max_yx(arr):\n    argmax_0 = np.argmax(arr, axis=0)\n    max_0 = arr[argmax_0, np.arange(arr.shape[1])]\n    argmax_1 = np.argmax(max_0)\n    max_yx_pos = np.array([argmax_0[argmax_1], argmax_1])\n    max_val = arr[max_yx_pos[0], max_yx_pos[1]]\n    return max_val, max_yx_pos\ndef get_max_heatmap_activation(tensor, gauss_sigma):\n    array = tensor.cpu().detach().numpy()\n    activations = ndimage.gaussian_filter(array, sigma=gauss_sigma, truncate=GAUSSIAN_TRUNCATE)",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "get_max_heatmap_activation",
        "kind": 2,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "def get_max_heatmap_activation(tensor, gauss_sigma):\n    array = tensor.cpu().detach().numpy()\n    activations = ndimage.gaussian_filter(array, sigma=gauss_sigma, truncate=GAUSSIAN_TRUNCATE)\n    max_val, max_pos = np_max_yx(activations)\n    return max_val, max_pos\ndef radial_errors_calcalation(pred, targ, gauss_sigma, orig_image_x=ORIG_IMAGE_X, orig_image_y=ORIG_IMAGE_Y):\n    example_radial_errors = np.zeros(N_LANDMARKS)\n    heatmap_y, heatmap_x = pred.shape[1:]\n    for i in range(N_LANDMARKS):\n        max_pred_act, pred_yx = get_max_heatmap_activation(pred[i], gauss_sigma)",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "radial_errors_calcalation",
        "kind": 2,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "def radial_errors_calcalation(pred, targ, gauss_sigma, orig_image_x=ORIG_IMAGE_X, orig_image_y=ORIG_IMAGE_Y):\n    example_radial_errors = np.zeros(N_LANDMARKS)\n    heatmap_y, heatmap_x = pred.shape[1:]\n    for i in range(N_LANDMARKS):\n        max_pred_act, pred_yx = get_max_heatmap_activation(pred[i], gauss_sigma)\n        _, true_yx = get_max_heatmap_activation(targ[i], gauss_sigma)\n        # Rescale to original resolution\n        rescale = np.array([ORIG_IMAGE_Y, ORIG_IMAGE_X]) / np.array([heatmap_y, heatmap_x])\n        pred_yx = np.around(pred_yx * rescale) / PIXELS_PER_MM\n        true_yx = np.around(true_yx * rescale) / PIXELS_PER_MM",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "radial_errors_batch",
        "kind": 2,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "def radial_errors_batch(preds, targs, gauss_sigma):\n    assert (preds.shape[0] == targs.shape[0])\n    batch_size = preds.shape[0]\n    batch_radial_errors = np.zeros((batch_size, N_LANDMARKS))\n    for i in range(batch_size):\n        batch_radial_errors[i] = radial_errors_calcalation(preds[i], targs[i], gauss_sigma)\n    return batch_radial_errors\ndef aug_and_save(img, img_name, label, aug_list, base_path):\n    kp = [list_to_kp(label)]\n    img = shrink.augment_image(img)",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "aug_and_save",
        "kind": 2,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "def aug_and_save(img, img_name, label, aug_list, base_path):\n    kp = [list_to_kp(label)]\n    img = shrink.augment_image(img)\n    kp = shrink.augment_keypoints(kp)\n    img_save_name = base_path + \"/\" + img_name + \"_aug{}\".format(0)\n    io.imsave(img_save_name + \".bmp\", img)\n    with open(img_save_name + \".txt\", \"w\") as lf:\n            stringified = [str(tup) for tup in kp_to_list(kp[0].keypoints)]\n            stringified = [s.replace(\"(\", \"\").replace(\")\",\"\") for s in stringified]\n            lf.write(\"\\n\".join(stringified))",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "GAUSSIAN_TRUNCATE",
        "kind": 5,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "GAUSSIAN_TRUNCATE = 1.0\nN_LANDMARKS = 19\ndef get_annots_for_image(annotations_path, image_path, rescaled_image_size=None, orig_image_size=np.array([ORIG_IMAGE_X, ORIG_IMAGE_Y])):\n    '''\n    Gets all the annations of an image and return in a simple array format of [[x1,y1], [x2,y2], ...] \n    '''\n    image_id = image_path.stem\n    annots = (annotations_path / f'{image_id}.txt').read_text()\n    annots = annots.split('\\n')[:N_LANDMARKS]\n    annots = [l.split(',') for l in annots]",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "N_LANDMARKS",
        "kind": 5,
        "importPath": "old-implementation.utilities.landmark_utils",
        "description": "old-implementation.utilities.landmark_utils",
        "peekOfCode": "N_LANDMARKS = 19\ndef get_annots_for_image(annotations_path, image_path, rescaled_image_size=None, orig_image_size=np.array([ORIG_IMAGE_X, ORIG_IMAGE_Y])):\n    '''\n    Gets all the annations of an image and return in a simple array format of [[x1,y1], [x2,y2], ...] \n    '''\n    image_id = image_path.stem\n    annots = (annotations_path / f'{image_id}.txt').read_text()\n    annots = annots.split('\\n')[:N_LANDMARKS]\n    annots = [l.split(',') for l in annots]\n    annots = [(float(l[0]), float(l[1])) for l in annots];",
        "detail": "old-implementation.utilities.landmark_utils",
        "documentation": {}
    },
    {
        "label": "draw_outline",
        "kind": 2,
        "importPath": "old-implementation.utilities.plotting",
        "description": "old-implementation.utilities.plotting",
        "peekOfCode": "def draw_outline(o, lw):\n    o.set_path_effects([patheffects.Stroke(linewidth=lw, foreground='black'), patheffects.Normal()])\ndef draw_text(ax, pos, label, fontsize, color='#00CC00', outline=2):\n    text = ax.text(*pos, label, verticalalignment='top', color=color, fontsize=fontsize)\n    draw_outline(text, outline)\ndef denorm(tensor_im):\n    tensor_im = tensor_im / 2.0 + 0.5\n    im = tensor_im.numpy()\n    im = np.squeeze(im)\n    return im",
        "detail": "old-implementation.utilities.plotting",
        "documentation": {}
    },
    {
        "label": "draw_text",
        "kind": 2,
        "importPath": "old-implementation.utilities.plotting",
        "description": "old-implementation.utilities.plotting",
        "peekOfCode": "def draw_text(ax, pos, label, fontsize, color='#00CC00', outline=2):\n    text = ax.text(*pos, label, verticalalignment='top', color=color, fontsize=fontsize)\n    draw_outline(text, outline)\ndef denorm(tensor_im):\n    tensor_im = tensor_im / 2.0 + 0.5\n    im = tensor_im.numpy()\n    im = np.squeeze(im)\n    return im\ndef plot_imgs(imgs, labels=None):\n    \"\"\" ",
        "detail": "old-implementation.utilities.plotting",
        "documentation": {}
    },
    {
        "label": "denorm",
        "kind": 2,
        "importPath": "old-implementation.utilities.plotting",
        "description": "old-implementation.utilities.plotting",
        "peekOfCode": "def denorm(tensor_im):\n    tensor_im = tensor_im / 2.0 + 0.5\n    im = tensor_im.numpy()\n    im = np.squeeze(im)\n    return im\ndef plot_imgs(imgs, labels=None):\n    \"\"\" \n    Plots tensor images with annotations.\n    \"\"\"\n    # Draw skull with landmarks",
        "detail": "old-implementation.utilities.plotting",
        "documentation": {}
    },
    {
        "label": "plot_imgs",
        "kind": 2,
        "importPath": "old-implementation.utilities.plotting",
        "description": "old-implementation.utilities.plotting",
        "peekOfCode": "def plot_imgs(imgs, labels=None):\n    \"\"\" \n    Plots tensor images with annotations.\n    \"\"\"\n    # Draw skull with landmarks\n    fig, axes = plt.subplots(6, len(imgs) // 6, figsize=(30, 20))\n    for i, ax in enumerate(axes.flat):\n        if type(imgs[i]) is torch.Tensor:\n            imgs[i] = denorm(imgs[i])\n        ax.imshow(np.squeeze(imgs[i]), cmap='gray')",
        "detail": "old-implementation.utilities.plotting",
        "documentation": {}
    },
    {
        "label": "draw_annot",
        "kind": 2,
        "importPath": "old-implementation.utilities.plotting",
        "description": "old-implementation.utilities.plotting",
        "peekOfCode": "def draw_annot(ax, pos, label, radius=40, fontsize=18, color='red', marker='x', alpha=1.0):\n    if marker is not None:\n        ax.scatter(pos[0], pos[1], s=radius, c=color, marker=marker, alpha=alpha)\n    if label is not None:\n        draw_text(ax, pos, label, fontsize, color=color)\ndef plot_img_with_heatmaps(img, heatmaps, gaussian_sigma):\n    \"\"\" \n    Plots tensor images with annotations.\n    \"\"\"\n    # Draw skull with landmarks",
        "detail": "old-implementation.utilities.plotting",
        "documentation": {}
    },
    {
        "label": "plot_img_with_heatmaps",
        "kind": 2,
        "importPath": "old-implementation.utilities.plotting",
        "description": "old-implementation.utilities.plotting",
        "peekOfCode": "def plot_img_with_heatmaps(img, heatmaps, gaussian_sigma):\n    \"\"\" \n    Plots tensor images with annotations.\n    \"\"\"\n    # Draw skull with landmarks\n    skull_fig, ax = plt.subplots(1, 1, figsize=(8, 8), frameon=False)\n    ax.set_axis_off()\n    if type(img) is torch.Tensor:\n        img = denorm(img)\n    ax.imshow(img, cmap='gray')",
        "detail": "old-implementation.utilities.plotting",
        "documentation": {}
    },
    {
        "label": "plot_training_result",
        "kind": 2,
        "importPath": "old-implementation.utilities.plotting",
        "description": "old-implementation.utilities.plotting",
        "peekOfCode": "def plot_training_result(trained_losses, trained_mre, trained_sdr_4mm):\n    plt.plot(trained_losses, label='Train loss')\n    plt.plot(trained_mre, label='Train Mean Root Error')\n    plt.plot(trained_sdr_4mm, label='Train Success Detection Rate')\n    plt.title('Loss at the end of each epoch')\n    plt.show();",
        "detail": "old-implementation.utilities.plotting",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "parser = argparse.ArgumentParser('')\nparser.add_argument('--MODE', type=str, required=True, choices=['ensemble'], help='Evaluation mode.')\nparser.add_argument('--DATA_SPLIT', type=str, default='test1', choices=['train', 'test1', 'test2'], help='Which data split to evaluate on.')\nparser.add_argument('--LOG_PATH', type=str, default='logs', help='Path to model logs.')\nparser.add_argument('--SAMPLES', type=int, default=15, help='Number of MC samples to use for prediction.')\nparser.add_argument('--MODEL_NAME', type=str, required=True, help='Name of the evaluated model(s).')\nparser.add_argument('--ANNOT_PATH', type=str, default='data/AnnotationsByMD/400_senior', help='Path to annotation data.')\nparser.add_argument('--IMAGES_PATH', type=str, default='data/images', help='Path to image data.')\nparser.add_argument('--IMAGE_SIZE', type=int, default=256, help='Size the test images will be rescaled to before being passed to the model.')\nargs = parser.parse_args()",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "args = parser.parse_args()\nargs.LOG_PATH = Path(args.LOG_PATH)\nargs.ANNOT_PATH = Path(args.ANNOT_PATH)\n# Get test files\ntest_dir = Path(args.IMAGES_PATH)/f'1px_3px/{args.IMAGE_SIZE}/{args.DATA_SPLIT}'\ntest_files = list_files(test_dir)\nn_test = len(test_files)\nprint(f'Evaluating performance metrics for model {args.MODEL_NAME}')\nprint(f'Split: {args.DATA_SPLIT}, no. images: {n_test}')\n# Compute true landmarks",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "args.LOG_PATH",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "args.LOG_PATH = Path(args.LOG_PATH)\nargs.ANNOT_PATH = Path(args.ANNOT_PATH)\n# Get test files\ntest_dir = Path(args.IMAGES_PATH)/f'1px_3px/{args.IMAGE_SIZE}/{args.DATA_SPLIT}'\ntest_files = list_files(test_dir)\nn_test = len(test_files)\nprint(f'Evaluating performance metrics for model {args.MODEL_NAME}')\nprint(f'Split: {args.DATA_SPLIT}, no. images: {n_test}')\n# Compute true landmarks\ntrue_landmarks_dict = OrderedDict()",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "args.ANNOT_PATH",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "args.ANNOT_PATH = Path(args.ANNOT_PATH)\n# Get test files\ntest_dir = Path(args.IMAGES_PATH)/f'1px_3px/{args.IMAGE_SIZE}/{args.DATA_SPLIT}'\ntest_files = list_files(test_dir)\nn_test = len(test_files)\nprint(f'Evaluating performance metrics for model {args.MODEL_NAME}')\nprint(f'Split: {args.DATA_SPLIT}, no. images: {n_test}')\n# Compute true landmarks\ntrue_landmarks_dict = OrderedDict()\nfor i, img_path in enumerate(test_files):",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "test_dir",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "test_dir = Path(args.IMAGES_PATH)/f'1px_3px/{args.IMAGE_SIZE}/{args.DATA_SPLIT}'\ntest_files = list_files(test_dir)\nn_test = len(test_files)\nprint(f'Evaluating performance metrics for model {args.MODEL_NAME}')\nprint(f'Split: {args.DATA_SPLIT}, no. images: {n_test}')\n# Compute true landmarks\ntrue_landmarks_dict = OrderedDict()\nfor i, img_path in enumerate(test_files):\n    true_landmarks_dict[img_path.name] = get_true_landmarks(args.ANNOT_PATH, img_path)\n# Load pre-generated model predictions from csvs",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "test_files",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "test_files = list_files(test_dir)\nn_test = len(test_files)\nprint(f'Evaluating performance metrics for model {args.MODEL_NAME}')\nprint(f'Split: {args.DATA_SPLIT}, no. images: {n_test}')\n# Compute true landmarks\ntrue_landmarks_dict = OrderedDict()\nfor i, img_path in enumerate(test_files):\n    true_landmarks_dict[img_path.name] = get_true_landmarks(args.ANNOT_PATH, img_path)\n# Load pre-generated model predictions from csvs\nmodel_log_dir = args.LOG_PATH/f'{args.DATA_SPLIT}/{args.MODE}/{args.MODEL_NAME}/predictions'",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "n_test",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "n_test = len(test_files)\nprint(f'Evaluating performance metrics for model {args.MODEL_NAME}')\nprint(f'Split: {args.DATA_SPLIT}, no. images: {n_test}')\n# Compute true landmarks\ntrue_landmarks_dict = OrderedDict()\nfor i, img_path in enumerate(test_files):\n    true_landmarks_dict[img_path.name] = get_true_landmarks(args.ANNOT_PATH, img_path)\n# Load pre-generated model predictions from csvs\nmodel_log_dir = args.LOG_PATH/f'{args.DATA_SPLIT}/{args.MODE}/{args.MODEL_NAME}/predictions'\npredictions_df = read_prediction_files_as_df(list_files(model_log_dir))",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "true_landmarks_dict",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "true_landmarks_dict = OrderedDict()\nfor i, img_path in enumerate(test_files):\n    true_landmarks_dict[img_path.name] = get_true_landmarks(args.ANNOT_PATH, img_path)\n# Load pre-generated model predictions from csvs\nmodel_log_dir = args.LOG_PATH/f'{args.DATA_SPLIT}/{args.MODE}/{args.MODEL_NAME}/predictions'\npredictions_df = read_prediction_files_as_df(list_files(model_log_dir))\n# Compute metrics\nradial_errors_all = np.zeros((len(test_files), N_LANDMARKS))\nfor i, image_file in enumerate(test_files):\n    # Compute the statistics across all samples for the image",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "model_log_dir",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "model_log_dir = args.LOG_PATH/f'{args.DATA_SPLIT}/{args.MODE}/{args.MODEL_NAME}/predictions'\npredictions_df = read_prediction_files_as_df(list_files(model_log_dir))\n# Compute metrics\nradial_errors_all = np.zeros((len(test_files), N_LANDMARKS))\nfor i, image_file in enumerate(test_files):\n    # Compute the statistics across all samples for the image\n    landmark_samples, activation_samples = get_predictions_for_image(predictions_df, image_file.name, args.SAMPLES)\n    predicted_landmarks_mean, predicted_landmarks_var = get_predicted_landmarks_for_image(landmark_samples)\n    activation_mean, activation_var = get_predicted_activations_for_image(activation_samples)\n    # Compute radial errors",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "predictions_df",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "predictions_df = read_prediction_files_as_df(list_files(model_log_dir))\n# Compute metrics\nradial_errors_all = np.zeros((len(test_files), N_LANDMARKS))\nfor i, image_file in enumerate(test_files):\n    # Compute the statistics across all samples for the image\n    landmark_samples, activation_samples = get_predictions_for_image(predictions_df, image_file.name, args.SAMPLES)\n    predicted_landmarks_mean, predicted_landmarks_var = get_predicted_landmarks_for_image(landmark_samples)\n    activation_mean, activation_var = get_predicted_activations_for_image(activation_samples)\n    # Compute radial errors\n    true_landmarks = true_landmarks_dict[image_file.name]",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "radial_errors_all",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "radial_errors_all = np.zeros((len(test_files), N_LANDMARKS))\nfor i, image_file in enumerate(test_files):\n    # Compute the statistics across all samples for the image\n    landmark_samples, activation_samples = get_predictions_for_image(predictions_df, image_file.name, args.SAMPLES)\n    predicted_landmarks_mean, predicted_landmarks_var = get_predicted_landmarks_for_image(landmark_samples)\n    activation_mean, activation_var = get_predicted_activations_for_image(activation_samples)\n    # Compute radial errors\n    true_landmarks = true_landmarks_dict[image_file.name]\n    radial_errors_all[i] = get_radial_errors_mm_for_image(true_landmarks, predicted_landmarks_mean)\nimage_file = test_files[4];",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "image_file",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "image_file = test_files[4];\nprint(test_files[4])\n# Compute the statistics across all samples for the image\nlandmark_samples, activation_samples = get_predictions_for_image(predictions_df, image_file.name, args.SAMPLES)\npredicted_landmarks_mean, predicted_landmarks_var = get_predicted_landmarks_for_image(landmark_samples)\nactivation_mean, activation_var = get_predicted_activations_for_image(activation_samples)\n# Compute radial errors\ntrue_landmarks = true_landmarks_dict[image_file.name]\nradial_errors_all = get_radial_errors_mm_for_image(true_landmarks, predicted_landmarks_mean)\nfor lm in range(len(true_landmarks)):",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "true_landmarks",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "true_landmarks = true_landmarks_dict[image_file.name]\nradial_errors_all = get_radial_errors_mm_for_image(true_landmarks, predicted_landmarks_mean)\nfor lm in range(len(true_landmarks)):\n    print(f\"True Landmarks: {true_landmarks[lm]}  - Predicted Landmark: {predicted_landmarks_mean[lm]}\"\n          f\"- MRE: {radial_errors_all[lm]:{2}.{2}}\\n\")\nmetrics = get_accuracy_metrics(radial_errors_all)\nprint_accuracy_metrics(metrics)\nprint('======================================')\n# print(f'Accuracy metrics for  model: {args.MODEL_NAME}, test split: {args.DATA_SPLIT}, mode: {args.MODE}, samples: {args.SAMPLES}')\n# metrics = get_accuracy_metrics(radial_errors_all)",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "radial_errors_all",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "radial_errors_all = get_radial_errors_mm_for_image(true_landmarks, predicted_landmarks_mean)\nfor lm in range(len(true_landmarks)):\n    print(f\"True Landmarks: {true_landmarks[lm]}  - Predicted Landmark: {predicted_landmarks_mean[lm]}\"\n          f\"- MRE: {radial_errors_all[lm]:{2}.{2}}\\n\")\nmetrics = get_accuracy_metrics(radial_errors_all)\nprint_accuracy_metrics(metrics)\nprint('======================================')\n# print(f'Accuracy metrics for  model: {args.MODEL_NAME}, test split: {args.DATA_SPLIT}, mode: {args.MODE}, samples: {args.SAMPLES}')\n# metrics = get_accuracy_metrics(radial_errors_all)\n# print_accuracy_metrics(metrics)",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "metrics",
        "kind": 5,
        "importPath": "old-implementation.evaluate",
        "description": "old-implementation.evaluate",
        "peekOfCode": "metrics = get_accuracy_metrics(radial_errors_all)\nprint_accuracy_metrics(metrics)\nprint('======================================')\n# print(f'Accuracy metrics for  model: {args.MODEL_NAME}, test split: {args.DATA_SPLIT}, mode: {args.MODE}, samples: {args.SAMPLES}')\n# metrics = get_accuracy_metrics(radial_errors_all)\n# print_accuracy_metrics(metrics)\n#\n# print (len(radial_errors_all))\n# get_radial_errors_mm_for_individual_landmarks(radial_errors_all)",
        "detail": "old-implementation.evaluate",
        "documentation": {}
    },
    {
        "label": "get_predicted_landmarks",
        "kind": 2,
        "importPath": "old-implementation.generate_predictions",
        "description": "old-implementation.generate_predictions",
        "peekOfCode": "def get_predicted_landmarks(pred_heatmaps, gauss_sigma):\n    n_landmarks = pred_heatmaps.shape[0]\n    heatmap_y, heatmap_x = pred_heatmaps.shape[1:]\n    pred_landmarks = np.zeros((n_landmarks, 2))\n    max_activations = np.zeros(n_landmarks)\n    for i in range(n_landmarks):\n        max_activation, pred_yx = get_max_heatmap_activation(pred_heatmaps[i], gauss_sigma)\n        rescale = np.array([ORIG_IMAGE_Y, ORIG_IMAGE_X]) / np.array([heatmap_y, heatmap_x])\n        pred_yx = np.around(pred_yx * rescale)\n        pred_landmarks[i] = pred_yx",
        "detail": "old-implementation.generate_predictions",
        "documentation": {}
    },
    {
        "label": "load_net",
        "kind": 2,
        "importPath": "old-implementation.generate_predictions",
        "description": "old-implementation.generate_predictions",
        "peekOfCode": "def load_net(path):\n    net = torch.load(path, map_location='cpu')\n    net.to(device)\n    return net\ndef enable_test_time_dropout(m):\n    if type(m) == nn.Dropout2d:\n        m.train()\ndef predict(model_path, test_time_dropout=False):\n    # Data frame\n    columns = ['file'] + [f'{i}_act' for i in range(N_LANDMARKS)] + \\",
        "detail": "old-implementation.generate_predictions",
        "documentation": {}
    },
    {
        "label": "enable_test_time_dropout",
        "kind": 2,
        "importPath": "old-implementation.generate_predictions",
        "description": "old-implementation.generate_predictions",
        "peekOfCode": "def enable_test_time_dropout(m):\n    if type(m) == nn.Dropout2d:\n        m.train()\ndef predict(model_path, test_time_dropout=False):\n    # Data frame\n    columns = ['file'] + [f'{i}_act' for i in range(N_LANDMARKS)] + \\\n              [f'{i}_y' for i in range(N_LANDMARKS)] + \\\n              [f'{i}_x' for i in range(N_LANDMARKS)]\n    index = np.arange(n_eval_images)\n    df = pd.DataFrame(columns=columns, index=index)",
        "detail": "old-implementation.generate_predictions",
        "documentation": {}
    },
    {
        "label": "predict",
        "kind": 2,
        "importPath": "old-implementation.generate_predictions",
        "description": "old-implementation.generate_predictions",
        "peekOfCode": "def predict(model_path, test_time_dropout=False):\n    # Data frame\n    columns = ['file'] + [f'{i}_act' for i in range(N_LANDMARKS)] + \\\n              [f'{i}_y' for i in range(N_LANDMARKS)] + \\\n              [f'{i}_x' for i in range(N_LANDMARKS)]\n    index = np.arange(n_eval_images)\n    df = pd.DataFrame(columns=columns, index=index)\n    # Model\n    net = load_net(model_path)\n    n_processed = 0",
        "detail": "old-implementation.generate_predictions",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "old-implementation.generate_predictions",
        "description": "old-implementation.generate_predictions",
        "peekOfCode": "device = 'cpu'\nparser = argparse.ArgumentParser('')\nparser.add_argument('--MODE', required=True, type=str, choices=['ensemble'], help='Evaluation mode.')\nparser.add_argument('--MODEL_PATH', required=True, type=str, help='Path to the evaluated model(s).')\nparser.add_argument('--DATA_SPLIT', type=str, choices=['train, test1, test2, test'], default='test1', help='Which data split to evaluate on.')\nparser.add_argument('--LOG_PATH', type=str, default='logs', help='Path to model(s).')\nparser.add_argument('--SAMPLES', type=int, default=15, help='Number of MC samples to use for prediction.')\nparser.add_argument('--IMAGES_PATH', type=str, default='data/images', help='Path to image data.')\nparser.add_argument('--ANNOT_PATH', type=str, help='Path to annotation data.')\nparser.add_argument('--IMAGE_SIZE', type=int, default=256, help='Size the test images will be rescaled to before being passed to the model.')",
        "detail": "old-implementation.generate_predictions",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "old-implementation.generate_predictions",
        "description": "old-implementation.generate_predictions",
        "peekOfCode": "parser = argparse.ArgumentParser('')\nparser.add_argument('--MODE', required=True, type=str, choices=['ensemble'], help='Evaluation mode.')\nparser.add_argument('--MODEL_PATH', required=True, type=str, help='Path to the evaluated model(s).')\nparser.add_argument('--DATA_SPLIT', type=str, choices=['train, test1, test2, test'], default='test1', help='Which data split to evaluate on.')\nparser.add_argument('--LOG_PATH', type=str, default='logs', help='Path to model(s).')\nparser.add_argument('--SAMPLES', type=int, default=15, help='Number of MC samples to use for prediction.')\nparser.add_argument('--IMAGES_PATH', type=str, default='data/images', help='Path to image data.')\nparser.add_argument('--ANNOT_PATH', type=str, help='Path to annotation data.')\nparser.add_argument('--IMAGE_SIZE', type=int, default=256, help='Size the test images will be rescaled to before being passed to the model.')\nparser.add_argument('--GAUSS_SIGMA', type=float, default=5, help='Sigma of the Gaussian kernel used to generate ground truth heatmaps for the landmarks.')",
        "detail": "old-implementation.generate_predictions",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "old-implementation.generate_predictions",
        "description": "old-implementation.generate_predictions",
        "peekOfCode": "args = parser.parse_args()\ndef get_predicted_landmarks(pred_heatmaps, gauss_sigma):\n    n_landmarks = pred_heatmaps.shape[0]\n    heatmap_y, heatmap_x = pred_heatmaps.shape[1:]\n    pred_landmarks = np.zeros((n_landmarks, 2))\n    max_activations = np.zeros(n_landmarks)\n    for i in range(n_landmarks):\n        max_activation, pred_yx = get_max_heatmap_activation(pred_heatmaps[i], gauss_sigma)\n        rescale = np.array([ORIG_IMAGE_Y, ORIG_IMAGE_X]) / np.array([heatmap_y, heatmap_x])\n        pred_yx = np.around(pred_yx * rescale)",
        "detail": "old-implementation.generate_predictions",
        "documentation": {}
    },
    {
        "label": "merge",
        "kind": 2,
        "importPath": "old-implementation.plot_test_images",
        "description": "old-implementation.plot_test_images",
        "peekOfCode": "def merge(list1, list2):\n    merged_list = [tuple([int(float(list1[i])), int(float(list2[i]))]) for i in range(0, len(list1))]\n    return merged_list\n# import sample coordinates from text as tuples\ndef extract_labels_from_txt(path):\n    with open(path, \"r\") as f:\n        # only first 19 are actual coords in dataset label files\n        coords_raw = f.readlines()[:19]\n        coords_raw = [tuple([int(float(s)) for s in t.split(\",\")]) for t in coords_raw]\n        return coords_raw",
        "detail": "old-implementation.plot_test_images",
        "documentation": {}
    },
    {
        "label": "extract_labels_from_txt",
        "kind": 2,
        "importPath": "old-implementation.plot_test_images",
        "description": "old-implementation.plot_test_images",
        "peekOfCode": "def extract_labels_from_txt(path):\n    with open(path, \"r\") as f:\n        # only first 19 are actual coords in dataset label files\n        coords_raw = f.readlines()[:19]\n        coords_raw = [tuple([int(float(s)) for s in t.split(\",\")]) for t in coords_raw]\n        return coords_raw\ndef extract_cordinate_from_cvs(path):\n    with open(path) as csvfile:\n        readCSV = csv.reader(csvfile, delimiter=',')\n        x_cordinates = []",
        "detail": "old-implementation.plot_test_images",
        "documentation": {}
    },
    {
        "label": "extract_cordinate_from_cvs",
        "kind": 2,
        "importPath": "old-implementation.plot_test_images",
        "description": "old-implementation.plot_test_images",
        "peekOfCode": "def extract_cordinate_from_cvs(path):\n    with open(path) as csvfile:\n        readCSV = csv.reader(csvfile, delimiter=',')\n        x_cordinates = []\n        y_cordinates = []\n        index = 0\n        for row in readCSV:\n            if (index == 1):\n                y_cords = row[21:40]\n                x_cords = row[40:]",
        "detail": "old-implementation.plot_test_images",
        "documentation": {}
    },
    {
        "label": "print_image",
        "kind": 2,
        "importPath": "old-implementation.plot_test_images",
        "description": "old-implementation.plot_test_images",
        "peekOfCode": "def print_image(img, labels):\n    print(img.shape)\n    plt.rcParams[\"figure.figsize\"] = [32, 18]\n    fig = plt.figure()\n    ax1 = fig.add_subplot(2, 2, 1)\n    ax2 = fig.add_subplot(2, 1, 1)\n    ax1.imshow(img, cmap=\"gray\")\n    # also plot resized image for later\n    orig_y, orig_x = img.shape[:2]\n    SCALE = 15",
        "detail": "old-implementation.plot_test_images",
        "documentation": {}
    },
    {
        "label": "display_image_and_cord",
        "kind": 2,
        "importPath": "old-implementation.plot_test_images",
        "description": "old-implementation.plot_test_images",
        "peekOfCode": "def display_image_and_cord(image_number, img_path, cord_path):\n    data = []\n    target = []\n    for i, fi in enumerate(os.listdir(img_path)):\n        if i < image_number:\n            loop_img = io.imread(img_path + fi, as_gray=True)\n            lf = fi[:-4] + \".txt\"\n            loop_labels = extract_labels_from_txt(cord_path + lf)\n            loop_labels = (np.array(loop_labels))\n            print(loop_img)",
        "detail": "old-implementation.plot_test_images",
        "documentation": {}
    },
    {
        "label": "SAMPLE_PATH",
        "kind": 5,
        "importPath": "old-implementation.plot_test_images",
        "description": "old-implementation.plot_test_images",
        "peekOfCode": "SAMPLE_PATH = \"data/images/128/test1/151.bmp\"\nTXT_PATH = \"logs/test1/ensemble/Ensemble/predictions/1.csv\"\n# import sample image\nimg = io.imread(SAMPLE_PATH, as_gray=True)\nprint(img.shape)\nimage_label = extract_cordinate_from_cvs(TXT_PATH)\n# plot_imgs(img)",
        "detail": "old-implementation.plot_test_images",
        "documentation": {}
    },
    {
        "label": "TXT_PATH",
        "kind": 5,
        "importPath": "old-implementation.plot_test_images",
        "description": "old-implementation.plot_test_images",
        "peekOfCode": "TXT_PATH = \"logs/test1/ensemble/Ensemble/predictions/1.csv\"\n# import sample image\nimg = io.imread(SAMPLE_PATH, as_gray=True)\nprint(img.shape)\nimage_label = extract_cordinate_from_cvs(TXT_PATH)\n# plot_imgs(img)",
        "detail": "old-implementation.plot_test_images",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "old-implementation.plot_test_images",
        "description": "old-implementation.plot_test_images",
        "peekOfCode": "img = io.imread(SAMPLE_PATH, as_gray=True)\nprint(img.shape)\nimage_label = extract_cordinate_from_cvs(TXT_PATH)\n# plot_imgs(img)",
        "detail": "old-implementation.plot_test_images",
        "documentation": {}
    },
    {
        "label": "image_label",
        "kind": 5,
        "importPath": "old-implementation.plot_test_images",
        "description": "old-implementation.plot_test_images",
        "peekOfCode": "image_label = extract_cordinate_from_cvs(TXT_PATH)\n# plot_imgs(img)",
        "detail": "old-implementation.plot_test_images",
        "documentation": {}
    },
    {
        "label": "train",
        "kind": 2,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "def train():\n    trained_examples = 0\n    train_loss, train_mre, train_sdr_2mm,train_sdr_2_5mm,train_sdr_3mm,train_sdr_4mm = 0, 0, 0, 0, 0, 0\n  #  print(train_dl)    \n    '''We train the model and continue with the extraction of necessary information'''\n    net.train() \n    for imgs, true_points, _ in train_dl:\n        imgs = imgs.to(device)\n        true_points = true_points.to(device)\n        optimizer.zero_grad()",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "validate",
        "kind": 2,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "def validate():\n    val_loss, val_mre, val_sdr_2mm, val_sdr_2_5mm, val_sdr_3mm, val_sdr_4mm = 0, 0, 0, 0, 0, 0\n    val_examples = 0\n    net.eval()\n    with torch.no_grad():\n        for imgs, true_points, _ in valid_dl:\n            imgs = imgs.to(device)\n            true_points = true_points.to(device)\n            pred_heatmaps = net(imgs)\n            loss = criterion(pred_heatmaps, true_points)",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "ORIG_IMAGE_SIZE",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "ORIG_IMAGE_SIZE = np.array([ORIG_IMAGE_X, ORIG_IMAGE_Y])  # WxH\nrandom_id = int(random.uniform(0, 99999999))\nparser = argparse.ArgumentParser()\nparser.add_argument('--DATA_PATH', type=str, default='./data', help='Define the root path to the dataset.')\nparser.add_argument('--MODEL_PATH', type=str, default='./trained', help='Path where the model checkpoints will be saved after it has been trained.')\nparser.add_argument('--MODEL_NAME', type=str, default=f'model_{random_id}')\nparser.add_argument('--EXPERIMENT_NAME', type=str, default=f'exp_{random_id}')\nparser.add_argument('--MODEL', type=str, default='unet')\nparser.add_argument('--FILTERS', type=lambda layers: [int(layer) for layer in layers.split(',')], default='64,128,256,512,1024')\nparser.add_argument('--DOWN_DROP', type=lambda layers: [float(layer) for layer in layers.split(',')], default='0.4,0.4,0.4,0.4')",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "random_id",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "random_id = int(random.uniform(0, 99999999))\nparser = argparse.ArgumentParser()\nparser.add_argument('--DATA_PATH', type=str, default='./data', help='Define the root path to the dataset.')\nparser.add_argument('--MODEL_PATH', type=str, default='./trained', help='Path where the model checkpoints will be saved after it has been trained.')\nparser.add_argument('--MODEL_NAME', type=str, default=f'model_{random_id}')\nparser.add_argument('--EXPERIMENT_NAME', type=str, default=f'exp_{random_id}')\nparser.add_argument('--MODEL', type=str, default='unet')\nparser.add_argument('--FILTERS', type=lambda layers: [int(layer) for layer in layers.split(',')], default='64,128,256,512,1024')\nparser.add_argument('--DOWN_DROP', type=lambda layers: [float(layer) for layer in layers.split(',')], default='0.4,0.4,0.4,0.4')\nparser.add_argument('--UP_DROP', type=lambda layers: [float(layer) for layer in layers.split(',')], default='0.4,0.4,0.4,0.4')",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument('--DATA_PATH', type=str, default='./data', help='Define the root path to the dataset.')\nparser.add_argument('--MODEL_PATH', type=str, default='./trained', help='Path where the model checkpoints will be saved after it has been trained.')\nparser.add_argument('--MODEL_NAME', type=str, default=f'model_{random_id}')\nparser.add_argument('--EXPERIMENT_NAME', type=str, default=f'exp_{random_id}')\nparser.add_argument('--MODEL', type=str, default='unet')\nparser.add_argument('--FILTERS', type=lambda layers: [int(layer) for layer in layers.split(',')], default='64,128,256,512,1024')\nparser.add_argument('--DOWN_DROP', type=lambda layers: [float(layer) for layer in layers.split(',')], default='0.4,0.4,0.4,0.4')\nparser.add_argument('--UP_DROP', type=lambda layers: [float(layer) for layer in layers.split(',')], default='0.4,0.4,0.4,0.4')\nparser.add_argument('--BATCH_SIZE', type=int, default=8)",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "args = parser.parse_args()\nprint(f'Training model {args.MODEL_NAME}')\n# Data paths\npath = Path(args.DATA_PATH)\nannotations_path = path / f'images/1px_3px/{args.IMAGE_SIZE}/train_annots'\nmodel_path = Path(args.MODEL_PATH) if args.MODEL_PATH is not None else path / 'models'\nmodel_path.mkdir(parents=True, exist_ok=True)\ntrain_path = path / f'images/1px_3px/{args.IMAGE_SIZE}/train'\n# Datasets, DataLoaders\nfnames = list_files(train_path)",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "path = Path(args.DATA_PATH)\nannotations_path = path / f'images/1px_3px/{args.IMAGE_SIZE}/train_annots'\nmodel_path = Path(args.MODEL_PATH) if args.MODEL_PATH is not None else path / 'models'\nmodel_path.mkdir(parents=True, exist_ok=True)\ntrain_path = path / f'images/1px_3px/{args.IMAGE_SIZE}/train'\n# Datasets, DataLoaders\nfnames = list_files(train_path)\nn_valid = int(args.VALID_RATIO * len(fnames))\ntrain_fnames = fnames[:-n_valid]\nvalid_fnames = fnames[-n_valid:]",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "annotations_path",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "annotations_path = path / f'images/1px_3px/{args.IMAGE_SIZE}/train_annots'\nmodel_path = Path(args.MODEL_PATH) if args.MODEL_PATH is not None else path / 'models'\nmodel_path.mkdir(parents=True, exist_ok=True)\ntrain_path = path / f'images/1px_3px/{args.IMAGE_SIZE}/train'\n# Datasets, DataLoaders\nfnames = list_files(train_path)\nn_valid = int(args.VALID_RATIO * len(fnames))\ntrain_fnames = fnames[:-n_valid]\nvalid_fnames = fnames[-n_valid:]\nprint(f'Number of train images: {len(train_fnames)}, Number of validation images: {len(valid_fnames)}')",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "model_path",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "model_path = Path(args.MODEL_PATH) if args.MODEL_PATH is not None else path / 'models'\nmodel_path.mkdir(parents=True, exist_ok=True)\ntrain_path = path / f'images/1px_3px/{args.IMAGE_SIZE}/train'\n# Datasets, DataLoaders\nfnames = list_files(train_path)\nn_valid = int(args.VALID_RATIO * len(fnames))\ntrain_fnames = fnames[:-n_valid]\nvalid_fnames = fnames[-n_valid:]\nprint(f'Number of train images: {len(train_fnames)}, Number of validation images: {len(valid_fnames)}')\nnum_workers = 0",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "train_path",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "train_path = path / f'images/1px_3px/{args.IMAGE_SIZE}/train'\n# Datasets, DataLoaders\nfnames = list_files(train_path)\nn_valid = int(args.VALID_RATIO * len(fnames))\ntrain_fnames = fnames[:-n_valid]\nvalid_fnames = fnames[-n_valid:]\nprint(f'Number of train images: {len(train_fnames)}, Number of validation images: {len(valid_fnames)}')\nnum_workers = 0\nelastic_trans = None\naffine_trans = None",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "fnames",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "fnames = list_files(train_path)\nn_valid = int(args.VALID_RATIO * len(fnames))\ntrain_fnames = fnames[:-n_valid]\nvalid_fnames = fnames[-n_valid:]\nprint(f'Number of train images: {len(train_fnames)}, Number of validation images: {len(valid_fnames)}')\nnum_workers = 0\nelastic_trans = None\naffine_trans = None\nif args.USE_ELASTIC_TRANS:\n    elastic_trans = ElasticTransform(sigma=args.ELASTIC_SIGMA, alpha=args.ELASTIC_ALPHA)",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "n_valid",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "n_valid = int(args.VALID_RATIO * len(fnames))\ntrain_fnames = fnames[:-n_valid]\nvalid_fnames = fnames[-n_valid:]\nprint(f'Number of train images: {len(train_fnames)}, Number of validation images: {len(valid_fnames)}')\nnum_workers = 0\nelastic_trans = None\naffine_trans = None\nif args.USE_ELASTIC_TRANS:\n    elastic_trans = ElasticTransform(sigma=args.ELASTIC_SIGMA, alpha=args.ELASTIC_ALPHA)\nif args.USE_AFFINE_TRANS:",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "train_fnames",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "train_fnames = fnames[:-n_valid]\nvalid_fnames = fnames[-n_valid:]\nprint(f'Number of train images: {len(train_fnames)}, Number of validation images: {len(valid_fnames)}')\nnum_workers = 0\nelastic_trans = None\naffine_trans = None\nif args.USE_ELASTIC_TRANS:\n    elastic_trans = ElasticTransform(sigma=args.ELASTIC_SIGMA, alpha=args.ELASTIC_ALPHA)\nif args.USE_AFFINE_TRANS:\n    angle = 5",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "valid_fnames",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "valid_fnames = fnames[-n_valid:]\nprint(f'Number of train images: {len(train_fnames)}, Number of validation images: {len(valid_fnames)}')\nnum_workers = 0\nelastic_trans = None\naffine_trans = None\nif args.USE_ELASTIC_TRANS:\n    elastic_trans = ElasticTransform(sigma=args.ELASTIC_SIGMA, alpha=args.ELASTIC_ALPHA)\nif args.USE_AFFINE_TRANS:\n    angle = 5\n    scales = [0.95, 1.05]",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "num_workers",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "num_workers = 0\nelastic_trans = None\naffine_trans = None\nif args.USE_ELASTIC_TRANS:\n    elastic_trans = ElasticTransform(sigma=args.ELASTIC_SIGMA, alpha=args.ELASTIC_ALPHA)\nif args.USE_AFFINE_TRANS:\n    angle = 5\n    scales = [0.95, 1.05]\n    tx, ty = 0.03, 0.03\n    affine_trans = AffineTransform(angle, scales, tx, ty)",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "elastic_trans",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "elastic_trans = None\naffine_trans = None\nif args.USE_ELASTIC_TRANS:\n    elastic_trans = ElasticTransform(sigma=args.ELASTIC_SIGMA, alpha=args.ELASTIC_ALPHA)\nif args.USE_AFFINE_TRANS:\n    angle = 5\n    scales = [0.95, 1.05]\n    tx, ty = 0.03, 0.03\n    affine_trans = AffineTransform(angle, scales, tx, ty)\ntrain_ds = LandmarkDataset(train_fnames, annotations_path, args.GAUSS_SIGMA, args.GAUSS_AMPLITUDE,",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "affine_trans",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "affine_trans = None\nif args.USE_ELASTIC_TRANS:\n    elastic_trans = ElasticTransform(sigma=args.ELASTIC_SIGMA, alpha=args.ELASTIC_ALPHA)\nif args.USE_AFFINE_TRANS:\n    angle = 5\n    scales = [0.95, 1.05]\n    tx, ty = 0.03, 0.03\n    affine_trans = AffineTransform(angle, scales, tx, ty)\ntrain_ds = LandmarkDataset(train_fnames, annotations_path, args.GAUSS_SIGMA, args.GAUSS_AMPLITUDE,\n                           elastic_trans=elastic_trans,",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "train_ds",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "train_ds = LandmarkDataset(train_fnames, annotations_path, args.GAUSS_SIGMA, args.GAUSS_AMPLITUDE,\n                           elastic_trans=elastic_trans,\n                           affine_trans=affine_trans, \n                           horizontal_flip=args.USE_HORIZONTAL_FLIP)\ntrain_dl = DataLoader(train_ds, args.BATCH_SIZE, shuffle=True, num_workers=num_workers)\nvalid_ds = LandmarkDataset(valid_fnames, annotations_path, args.GAUSS_SIGMA, args.GAUSS_AMPLITUDE)\nvalid_dl = DataLoader(valid_ds, args.BATCH_SIZE, shuffle=False, num_workers=num_workers)\n\"\"\"\nCUDA is a parallel computing platform and programming model that makes using a GPU \nfor general purpose computing simple and elegant. ",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "train_dl",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "train_dl = DataLoader(train_ds, args.BATCH_SIZE, shuffle=True, num_workers=num_workers)\nvalid_ds = LandmarkDataset(valid_fnames, annotations_path, args.GAUSS_SIGMA, args.GAUSS_AMPLITUDE)\nvalid_dl = DataLoader(valid_ds, args.BATCH_SIZE, shuffle=False, num_workers=num_workers)\n\"\"\"\nCUDA is a parallel computing platform and programming model that makes using a GPU \nfor general purpose computing simple and elegant. \n\"\"\"\ndevice = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\nprint(f'Graphic Cart Used for the experiment: {device}')\n# unet model",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "valid_ds",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "valid_ds = LandmarkDataset(valid_fnames, annotations_path, args.GAUSS_SIGMA, args.GAUSS_AMPLITUDE)\nvalid_dl = DataLoader(valid_ds, args.BATCH_SIZE, shuffle=False, num_workers=num_workers)\n\"\"\"\nCUDA is a parallel computing platform and programming model that makes using a GPU \nfor general purpose computing simple and elegant. \n\"\"\"\ndevice = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\nprint(f'Graphic Cart Used for the experiment: {device}')\n# unet model\nif args.MODEL == 'unet':",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "valid_dl",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "valid_dl = DataLoader(valid_ds, args.BATCH_SIZE, shuffle=False, num_workers=num_workers)\n\"\"\"\nCUDA is a parallel computing platform and programming model that makes using a GPU \nfor general purpose computing simple and elegant. \n\"\"\"\ndevice = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\nprint(f'Graphic Cart Used for the experiment: {device}')\n# unet model\nif args.MODEL == 'unet':\n    net = UNet(in_ch=3, out_ch=N_LANDMARKS, down_drop=args.DOWN_DROP, up_drop=args.UP_DROP)",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "device",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\nprint(f'Graphic Cart Used for the experiment: {device}')\n# unet model\nif args.MODEL == 'unet':\n    net = UNet(in_ch=3, out_ch=N_LANDMARKS, down_drop=args.DOWN_DROP, up_drop=args.UP_DROP)\nnet.to(device);\n# count_parameters(net)\n# Optimizer + loss\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=args.LEARN_RATE, weight_decay=args.WEIGHT_DECAY)",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "criterion",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "criterion = nn.MSELoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=args.LEARN_RATE, weight_decay=args.WEIGHT_DECAY)\n\"\"\"\nReduce learning rate when a metric has stopped improving. Models often benefit from reducing the \nlearning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if \nno improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n\"\"\"\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=args.OPTIM_PATIENCE, verbose=True)\nstart_time = time.time()\ntrained_losses = []",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "optimizer",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "optimizer = torch.optim.Adam(net.parameters(), lr=args.LEARN_RATE, weight_decay=args.WEIGHT_DECAY)\n\"\"\"\nReduce learning rate when a metric has stopped improving. Models often benefit from reducing the \nlearning rate by a factor of 2-10 once learning stagnates. This callback monitors a quantity and if \nno improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n\"\"\"\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=args.OPTIM_PATIENCE, verbose=True)\nstart_time = time.time()\ntrained_losses = []\ntrained_mre = []",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "scheduler",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=args.OPTIM_PATIENCE, verbose=True)\nstart_time = time.time()\ntrained_losses = []\ntrained_mre = []\n#Success Detection Rate\ntrained_sdr_4mm = [] \ndef train():\n    trained_examples = 0\n    train_loss, train_mre, train_sdr_2mm,train_sdr_2_5mm,train_sdr_3mm,train_sdr_4mm = 0, 0, 0, 0, 0, 0\n  #  print(train_dl)    ",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "start_time",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "start_time = time.time()\ntrained_losses = []\ntrained_mre = []\n#Success Detection Rate\ntrained_sdr_4mm = [] \ndef train():\n    trained_examples = 0\n    train_loss, train_mre, train_sdr_2mm,train_sdr_2_5mm,train_sdr_3mm,train_sdr_4mm = 0, 0, 0, 0, 0, 0\n  #  print(train_dl)    \n    '''We train the model and continue with the extraction of necessary information'''",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "trained_losses",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "trained_losses = []\ntrained_mre = []\n#Success Detection Rate\ntrained_sdr_4mm = [] \ndef train():\n    trained_examples = 0\n    train_loss, train_mre, train_sdr_2mm,train_sdr_2_5mm,train_sdr_3mm,train_sdr_4mm = 0, 0, 0, 0, 0, 0\n  #  print(train_dl)    \n    '''We train the model and continue with the extraction of necessary information'''\n    net.train() ",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "trained_mre",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "trained_mre = []\n#Success Detection Rate\ntrained_sdr_4mm = [] \ndef train():\n    trained_examples = 0\n    train_loss, train_mre, train_sdr_2mm,train_sdr_2_5mm,train_sdr_3mm,train_sdr_4mm = 0, 0, 0, 0, 0, 0\n  #  print(train_dl)    \n    '''We train the model and continue with the extraction of necessary information'''\n    net.train() \n    for imgs, true_points, _ in train_dl:",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "trained_sdr_4mm",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "trained_sdr_4mm = [] \ndef train():\n    trained_examples = 0\n    train_loss, train_mre, train_sdr_2mm,train_sdr_2_5mm,train_sdr_3mm,train_sdr_4mm = 0, 0, 0, 0, 0, 0\n  #  print(train_dl)    \n    '''We train the model and continue with the extraction of necessary information'''\n    net.train() \n    for imgs, true_points, _ in train_dl:\n        imgs = imgs.to(device)\n        true_points = true_points.to(device)",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "best_val_loss",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "best_val_loss = None\nnum_bad_epochs = 0\ntry:\n    for e in range(1, args.EPOCHS + 1):\n        train_loss = train()\n        val_loss, val_sdr_2mm, val_sdr_2_5mm, val_sdr_3mm, val_sdr_4mm, val_mre = validate()\n        scheduler.step(val_loss)\n        if args.SAVE_EPOCHS is not None and e in args.SAVE_EPOCHS:\n            print(f'Saving model checkpoint (one of {args.SAVE_EPOCHS} requested).')\n            with open(model_path / f'{args.MODEL_NAME}_e_{e}.pth', 'wb') as f:",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "num_bad_epochs",
        "kind": 5,
        "importPath": "old-implementation.train",
        "description": "old-implementation.train",
        "peekOfCode": "num_bad_epochs = 0\ntry:\n    for e in range(1, args.EPOCHS + 1):\n        train_loss = train()\n        val_loss, val_sdr_2mm, val_sdr_2_5mm, val_sdr_3mm, val_sdr_4mm, val_mre = validate()\n        scheduler.step(val_loss)\n        if args.SAVE_EPOCHS is not None and e in args.SAVE_EPOCHS:\n            print(f'Saving model checkpoint (one of {args.SAVE_EPOCHS} requested).')\n            with open(model_path / f'{args.MODEL_NAME}_e_{e}.pth', 'wb') as f:\n                torch.save(net, f)",
        "detail": "old-implementation.train",
        "documentation": {}
    },
    {
        "label": "DatasetExtractor",
        "kind": 6,
        "importPath": "scripts.extract_dataset",
        "description": "scripts.extract_dataset",
        "peekOfCode": "class DatasetExtractor:\n    \"\"\"Handles extraction of nested ZIP and RAR archives\"\"\"\n    def __init__(self, input_path: str, output_path: str):\n        self.input_path = Path(input_path)\n        self.output_path = Path(output_path)\n        self.extracted_files = []\n        self.errors = []\n        # Create output directory\n        self.output_path.mkdir(parents=True, exist_ok=True)\n        # Create logs directory",
        "detail": "scripts.extract_dataset",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "scripts.extract_dataset",
        "description": "scripts.extract_dataset",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(\n        description=\"Extract MAHT-Net dataset with nested archive support\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n        epilog=\"\"\"\nExamples:\n  # Extract default dataset\n  python scripts/extract_dataset.py\n  # Extract custom dataset\n  python scripts/extract_dataset.py --input data/raw/custom.zip --output data/processed",
        "detail": "scripts.extract_dataset",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "scripts.extract_dataset",
        "description": "scripts.extract_dataset",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass DatasetExtractor:\n    \"\"\"Handles extraction of nested ZIP and RAR archives\"\"\"\n    def __init__(self, input_path: str, output_path: str):\n        self.input_path = Path(input_path)\n        self.output_path = Path(output_path)\n        self.extracted_files = []\n        self.errors = []\n        # Create output directory\n        self.output_path.mkdir(parents=True, exist_ok=True)",
        "detail": "scripts.extract_dataset",
        "documentation": {}
    },
    {
        "label": "CephalometricDataset",
        "kind": 6,
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "peekOfCode": "class CephalometricDataset(Dataset):\n    \"\"\"\n    Dataset class for cephalometric landmark detection\n    Supports multiple cephalometric datasets with standardized 7-landmark annotation:\n    1. Nasion (N)\n    2. Sella (S) \n    3. Articulare (Ar)\n    4. Gonion (Go)\n    5. Menton (Me)\n    6. Pogonion (Pog)",
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "create_dataloaders",
        "kind": 2,
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "peekOfCode": "def create_dataloaders(data_dir: str,\n                      batch_size: int = 8,\n                      num_workers: int = 4,\n                      image_size: Tuple[int, int] = (512, 512),\n                      heatmap_size: Tuple[int, int] = (64, 64)) -> Dict[str, DataLoader]:\n    \"\"\"\n    Create train, validation, and test dataloaders\n    Args:\n        data_dir: Root directory containing the dataset\n        batch_size: Batch size for training",
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "visualize_sample",
        "kind": 2,
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "peekOfCode": "def visualize_sample(dataset: CephalometricDataset, \n                    idx: int, \n                    save_path: Optional[str] = None) -> np.ndarray:\n    \"\"\"\n    Visualize a dataset sample with landmarks and heatmaps\n    Args:\n        dataset: CephalometricDataset instance\n        idx: Sample index to visualize\n        save_path: Optional path to save the visualization\n    Returns:",
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.data.dataset",
        "description": "src.data.dataset",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass CephalometricDataset(Dataset):\n    \"\"\"\n    Dataset class for cephalometric landmark detection\n    Supports multiple cephalometric datasets with standardized 7-landmark annotation:\n    1. Nasion (N)\n    2. Sella (S) \n    3. Articulare (Ar)\n    4. Gonion (Go)\n    5. Menton (Me)",
        "detail": "src.data.dataset",
        "documentation": {}
    },
    {
        "label": "CephalometricDataProcessor",
        "kind": 6,
        "importPath": "src.data.preprocess",
        "description": "src.data.preprocess",
        "peekOfCode": "class CephalometricDataProcessor:\n    \"\"\"\n    Comprehensive data processor for cephalometric datasets\n    Handles multiple dataset formats and standardizes to MAHT-Net format\n    \"\"\"\n    def __init__(self, \n                 output_dir: str,\n                 target_size: Tuple[int, int] = (512, 512),\n                 quality_check: bool = True):\n        \"\"\"",
        "detail": "src.data.preprocess",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "src.data.preprocess",
        "description": "src.data.preprocess",
        "peekOfCode": "def main():\n    \"\"\"Main function for command-line usage\"\"\"\n    parser = argparse.ArgumentParser(description=\"Preprocess cephalometric datasets for MAHT-Net\")\n    parser.add_argument('--input-dir', required=True, help='Input directory containing raw data')\n    parser.add_argument('--output-dir', required=True, help='Output directory for processed data')\n    parser.add_argument('--dataset-name', required=True, help='Name of the dataset')\n    parser.add_argument('--annotation-format', default='auto', choices=['auto', 'json', 'csv', 'xml'],\n                       help='Format of annotation files')\n    parser.add_argument('--target-size', nargs=2, type=int, default=[512, 512],\n                       help='Target image size (width height)')",
        "detail": "src.data.preprocess",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.data.preprocess",
        "description": "src.data.preprocess",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass CephalometricDataProcessor:\n    \"\"\"\n    Comprehensive data processor for cephalometric datasets\n    Handles multiple dataset formats and standardizes to MAHT-Net format\n    \"\"\"\n    def __init__(self, \n                 output_dir: str,\n                 target_size: Tuple[int, int] = (512, 512),\n                 quality_check: bool = True):",
        "detail": "src.data.preprocess",
        "documentation": {}
    },
    {
        "label": "MultiScaleFeatureExtractor",
        "kind": 6,
        "importPath": "src.models.maht_net",
        "description": "src.models.maht_net",
        "peekOfCode": "class MultiScaleFeatureExtractor(nn.Module):\n    \"\"\"\n    CNN-based multi-scale feature extractor using EfficientNet-B3 backbone\n    Extracts hierarchical features at 5 different scales for comprehensive analysis\n    \"\"\"\n    def __init__(self, pretrained: bool = True):\n        super().__init__()\n        # EfficientNet-B3 backbone for robust feature extraction\n        self.backbone = timm.create_model(\n            'efficientnet_b3', ",
        "detail": "src.models.maht_net",
        "documentation": {}
    },
    {
        "label": "SpatialAttentionModule",
        "kind": 6,
        "importPath": "src.models.maht_net",
        "description": "src.models.maht_net",
        "peekOfCode": "class SpatialAttentionModule(nn.Module):\n    \"\"\"\n    Spatial attention mechanism for enhanced feature focusing\n    \"\"\"\n    def __init__(self, in_channels: int, reduction: int = 16):\n        super().__init__()\n        self.attention = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(in_channels, in_channels // reduction, 1),\n            nn.ReLU(inplace=True),",
        "detail": "src.models.maht_net",
        "documentation": {}
    },
    {
        "label": "VisionTransformerBottleneck",
        "kind": 6,
        "importPath": "src.models.maht_net",
        "description": "src.models.maht_net",
        "peekOfCode": "class VisionTransformerBottleneck(nn.Module):\n    \"\"\"\n    Vision Transformer bottleneck for global context modeling\n    Processes the deepest CNN features with transformer attention\n    \"\"\"\n    def __init__(self, \n                 feature_dim: int = 384,\n                 num_heads: int = 8,\n                 num_layers: int = 4,\n                 mlp_ratio: int = 4):",
        "detail": "src.models.maht_net",
        "documentation": {}
    },
    {
        "label": "AttentionGatedDecoder",
        "kind": 6,
        "importPath": "src.models.maht_net",
        "description": "src.models.maht_net",
        "peekOfCode": "class AttentionGatedDecoder(nn.Module):\n    \"\"\"\n    Attention-gated decoder with FPN-style multi-scale feature fusion\n    Combines features from different scales with attention mechanisms\n    \"\"\"\n    def __init__(self, feature_dims: List[int], output_dim: int = 256):\n        super().__init__()\n        self.feature_dims = feature_dims\n        self.output_dim = output_dim\n        # Lateral connections for FPN",
        "detail": "src.models.maht_net",
        "documentation": {}
    },
    {
        "label": "LandmarkDetectionHead",
        "kind": 6,
        "importPath": "src.models.maht_net",
        "description": "src.models.maht_net",
        "peekOfCode": "class LandmarkDetectionHead(nn.Module):\n    \"\"\"\n    Dual-output detection head for heatmap regression and coordinate prediction\n    Includes uncertainty quantification for clinical safety\n    \"\"\"\n    def __init__(self, \n                 input_dim: int = 256, \n                 num_landmarks: int = 7,\n                 heatmap_size: int = 64):\n        super().__init__()",
        "detail": "src.models.maht_net",
        "documentation": {}
    },
    {
        "label": "MAHTNet",
        "kind": 6,
        "importPath": "src.models.maht_net",
        "description": "src.models.maht_net",
        "peekOfCode": "class MAHTNet(nn.Module):\n    \"\"\"\n    MAHT-Net: Multi-Stage Attention-enhanced Hybrid Transformer Network\n    Main architecture combining CNN feature extraction, Transformer bottleneck,\n    and attention-gated decoding for precise cephalometric landmark detection.\n    \"\"\"\n    def __init__(self, \n                 num_landmarks: int = 7,\n                 pretrained: bool = True,\n                 heatmap_size: int = 64):",
        "detail": "src.models.maht_net",
        "documentation": {}
    },
    {
        "label": "create_maht_net",
        "kind": 2,
        "importPath": "src.models.maht_net",
        "description": "src.models.maht_net",
        "peekOfCode": "def create_maht_net(num_landmarks: int = 7, \n                   pretrained: bool = True,\n                   heatmap_size: int = 64) -> MAHTNet:\n    \"\"\"\n    Factory function to create MAHT-Net model\n    Args:\n        num_landmarks: Number of landmarks to detect (default: 7 for cephalometric)\n        pretrained: Use pretrained CNN backbone (recommended)\n        heatmap_size: Output heatmap resolution\n    Returns:",
        "detail": "src.models.maht_net",
        "documentation": {}
    },
    {
        "label": "MAHTNetTrainer",
        "kind": 6,
        "importPath": "src.training.trainer",
        "description": "src.training.trainer",
        "peekOfCode": "class MAHTNetTrainer:\n    \"\"\"\n    Comprehensive trainer for MAHT-Net with progressive 3-stage training strategy\n    Stage 1: CNN Baseline Training (Weeks 9-12)\n    Stage 2: Transformer Integration (Weeks 13-16) \n    Stage 3: Full Multi-Task Learning (Weeks 17-20)\n    \"\"\"\n    def __init__(self,\n                 model: MAHTNet,\n                 train_loader: DataLoader,",
        "detail": "src.training.trainer",
        "documentation": {}
    },
    {
        "label": "train_maht_net",
        "kind": 2,
        "importPath": "src.training.trainer",
        "description": "src.training.trainer",
        "peekOfCode": "def train_maht_net(config_path: str):\n    \"\"\"\n    Main training function for MAHT-Net with progressive 3-stage strategy\n    Args:\n        config_path: Path to training configuration file\n    \"\"\"\n    # Load configuration\n    with open(config_path, 'r') as f:\n        config = json.load(f)\n    # Setup device",
        "detail": "src.training.trainer",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "src.training.trainer",
        "description": "src.training.trainer",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass MAHTNetTrainer:\n    \"\"\"\n    Comprehensive trainer for MAHT-Net with progressive 3-stage training strategy\n    Stage 1: CNN Baseline Training (Weeks 9-12)\n    Stage 2: Transformer Integration (Weeks 13-16) \n    Stage 3: Full Multi-Task Learning (Weeks 17-20)\n    \"\"\"\n    def __init__(self,\n                 model: MAHTNet,",
        "detail": "src.training.trainer",
        "documentation": {}
    },
    {
        "label": "HeatmapLoss",
        "kind": 6,
        "importPath": "src.utils.losses",
        "description": "src.utils.losses",
        "peekOfCode": "class HeatmapLoss(nn.Module):\n    \"\"\"\n    Loss function for heatmap regression with focal loss modification\n    Handles class imbalance in landmark detection\n    \"\"\"\n    def __init__(self, alpha: float = 2.0, beta: float = 4.0):\n        super().__init__()\n        self.alpha = alpha  # Focal loss alpha\n        self.beta = beta    # Focal loss beta\n    def forward(self, pred_heatmaps: torch.Tensor, target_heatmaps: torch.Tensor) -> torch.Tensor:",
        "detail": "src.utils.losses",
        "documentation": {}
    },
    {
        "label": "CoordinateLoss",
        "kind": 6,
        "importPath": "src.utils.losses",
        "description": "src.utils.losses",
        "peekOfCode": "class CoordinateLoss(nn.Module):\n    \"\"\"\n    Loss function for direct coordinate regression\n    Uses smooth L1 loss for robustness to outliers\n    \"\"\"\n    def __init__(self, reduction: str = 'mean'):\n        super().__init__()\n        self.reduction = reduction\n    def forward(self, pred_coords: torch.Tensor, target_coords: torch.Tensor) -> torch.Tensor:\n        \"\"\"",
        "detail": "src.utils.losses",
        "documentation": {}
    },
    {
        "label": "UncertaintyLoss",
        "kind": 6,
        "importPath": "src.utils.losses",
        "description": "src.utils.losses",
        "peekOfCode": "class UncertaintyLoss(nn.Module):\n    \"\"\"\n    Loss function for uncertainty estimation\n    Encourages higher uncertainty for more difficult predictions\n    \"\"\"\n    def __init__(self, lambda_var: float = 1.0):\n        super().__init__()\n        self.lambda_var = lambda_var\n    def forward(self, \n                pred_coords: torch.Tensor, ",
        "detail": "src.utils.losses",
        "documentation": {}
    },
    {
        "label": "CombinedLandmarkLoss",
        "kind": 6,
        "importPath": "src.utils.losses",
        "description": "src.utils.losses",
        "peekOfCode": "class CombinedLandmarkLoss(nn.Module):\n    \"\"\"\n    Combined multi-task loss for MAHT-Net\n    Balances heatmap regression, coordinate prediction, and uncertainty estimation\n    \"\"\"\n    def __init__(self,\n                 heatmap_weight: float = 1.0,\n                 coord_weight: float = 1.0,\n                 uncertainty_weight: float = 0.1,\n                 adaptive_weighting: bool = True):",
        "detail": "src.utils.losses",
        "documentation": {}
    },
    {
        "label": "PerceptualLoss",
        "kind": 6,
        "importPath": "src.utils.losses",
        "description": "src.utils.losses",
        "peekOfCode": "class PerceptualLoss(nn.Module):\n    \"\"\"\n    Perceptual loss using pretrained VGG features\n    Helps with spatial consistency in heatmaps\n    \"\"\"\n    def __init__(self, layers: list = ['relu1_2', 'relu2_2', 'relu3_3']):\n        super().__init__()\n        # Load pretrained VGG19\n        vgg = torch.hub.load('pytorch/vision:v0.10.0', 'vgg19', pretrained=True)\n        self.features = vgg.features",
        "detail": "src.utils.losses",
        "documentation": {}
    },
    {
        "label": "ConsistencyLoss",
        "kind": 6,
        "importPath": "src.utils.losses",
        "description": "src.utils.losses",
        "peekOfCode": "class ConsistencyLoss(nn.Module):\n    \"\"\"\n    Consistency loss between heatmap and coordinate predictions\n    Ensures spatial consistency between different output heads\n    \"\"\"\n    def __init__(self, temperature: float = 1.0):\n        super().__init__()\n        self.temperature = temperature\n    def forward(self, \n                pred_heatmaps: torch.Tensor, ",
        "detail": "src.utils.losses",
        "documentation": {}
    },
    {
        "label": "create_loss_function",
        "kind": 2,
        "importPath": "src.utils.losses",
        "description": "src.utils.losses",
        "peekOfCode": "def create_loss_function(config: dict) -> nn.Module:\n    \"\"\"\n    Factory function to create loss function based on configuration\n    Args:\n        config: Loss configuration dictionary\n    Returns:\n        Configured loss function\n    \"\"\"\n    loss_type = config.get('type', 'combined')\n    if loss_type == 'combined':",
        "detail": "src.utils.losses",
        "documentation": {}
    },
    {
        "label": "compute_landmark_metrics",
        "kind": 2,
        "importPath": "src.utils.metrics",
        "description": "src.utils.metrics",
        "peekOfCode": "def compute_landmark_metrics(predictions: torch.Tensor, \n                           targets: torch.Tensor,\n                           pixel_spacing: float = 0.1) -> Dict[str, float]:\n    \"\"\"\n    Compute comprehensive landmark detection metrics\n    Args:\n        predictions: Predicted landmarks [B, N, 2]\n        targets: Ground truth landmarks [B, N, 2] \n        pixel_spacing: Pixel spacing in mm (default: 0.1mm)\n    Returns:",
        "detail": "src.utils.metrics",
        "documentation": {}
    },
    {
        "label": "compute_clinical_accuracy_metrics",
        "kind": 2,
        "importPath": "src.utils.metrics",
        "description": "src.utils.metrics",
        "peekOfCode": "def compute_clinical_accuracy_metrics(predictions: torch.Tensor,\n                                   targets: torch.Tensor,\n                                   uncertainties: Optional[torch.Tensor] = None,\n                                   pixel_spacing: float = 0.1) -> Dict[str, float]:\n    \"\"\"\n    Compute clinical accuracy metrics following orthodontic standards\n    Args:\n        predictions: Predicted landmarks [B, N, 2]\n        targets: Ground truth landmarks [B, N, 2]\n        uncertainties: Prediction uncertainties [B, N] (optional)",
        "detail": "src.utils.metrics",
        "documentation": {}
    },
    {
        "label": "compute_inter_observer_metrics",
        "kind": 2,
        "importPath": "src.utils.metrics",
        "description": "src.utils.metrics",
        "peekOfCode": "def compute_inter_observer_metrics(predictions_a: torch.Tensor,\n                                 predictions_b: torch.Tensor,\n                                 pixel_spacing: float = 0.1) -> Dict[str, float]:\n    \"\"\"\n    Compute inter-observer agreement metrics\n    Args:\n        predictions_a: First observer predictions [B, N, 2]\n        predictions_b: Second observer predictions [B, N, 2]\n        pixel_spacing: Pixel spacing in mm\n    Returns:",
        "detail": "src.utils.metrics",
        "documentation": {}
    },
    {
        "label": "visualize_landmark_errors",
        "kind": 2,
        "importPath": "src.utils.metrics",
        "description": "src.utils.metrics",
        "peekOfCode": "def visualize_landmark_errors(predictions: torch.Tensor,\n                            targets: torch.Tensor,\n                            landmark_names: List[str],\n                            save_path: Optional[str] = None,\n                            pixel_spacing: float = 0.1) -> plt.Figure:\n    \"\"\"\n    Create comprehensive visualization of landmark detection errors\n    Args:\n        predictions: Predicted landmarks [B, N, 2]\n        targets: Ground truth landmarks [B, N, 2]",
        "detail": "src.utils.metrics",
        "documentation": {}
    },
    {
        "label": "create_metrics_report",
        "kind": 2,
        "importPath": "src.utils.metrics",
        "description": "src.utils.metrics",
        "peekOfCode": "def create_metrics_report(metrics: Dict[str, float],\n                        landmark_names: List[str],\n                        save_path: Optional[str] = None) -> str:\n    \"\"\"\n    Create a comprehensive metrics report\n    Args:\n        metrics: Computed metrics dictionary\n        landmark_names: Names of landmarks\n        save_path: Optional path to save report\n    Returns:",
        "detail": "src.utils.metrics",
        "documentation": {}
    },
    {
        "label": "MAHTNetEvaluator",
        "kind": 6,
        "importPath": "evaluate",
        "description": "evaluate",
        "peekOfCode": "class MAHTNetEvaluator:\n    \"\"\"\n    Comprehensive evaluator for MAHT-Net with clinical validation\n    \"\"\"\n    def __init__(self,\n                 model: torch.nn.Module,\n                 device: torch.device,\n                 config: Dict):\n        self.model = model.to(device)\n        self.device = device",
        "detail": "evaluate",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "evaluate",
        "description": "evaluate",
        "peekOfCode": "def parse_args():\n    \"\"\"Parse command line arguments\"\"\"\n    parser = argparse.ArgumentParser(description=\"Evaluate MAHT-Net for Cephalometric Landmark Detection\")\n    parser.add_argument(\n        '--checkpoint',\n        type=str,\n        required=True,\n        help='Path to model checkpoint'\n    )\n    parser.add_argument(",
        "detail": "evaluate",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "evaluate",
        "description": "evaluate",
        "peekOfCode": "def main():\n    \"\"\"Main evaluation function\"\"\"\n    args = parse_args()\n    # Setup device\n    if args.gpu is not None:\n        device = torch.device(f'cuda:{args.gpu}' if torch.cuda.is_available() else 'cpu')\n    else:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    logger.info(f\"  Using device: {device}\")\n    # Load configuration",
        "detail": "evaluate",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "evaluate",
        "description": "evaluate",
        "peekOfCode": "logger = logging.getLogger(__name__)\nclass MAHTNetEvaluator:\n    \"\"\"\n    Comprehensive evaluator for MAHT-Net with clinical validation\n    \"\"\"\n    def __init__(self,\n                 model: torch.nn.Module,\n                 device: torch.device,\n                 config: Dict):\n        self.model = model.to(device)",
        "detail": "evaluate",
        "documentation": {}
    },
    {
        "label": "read_readme",
        "kind": 2,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "def read_readme():\n    readme_path = os.path.join(os.path.dirname(__file__), 'README.md')\n    with open(readme_path, 'r', encoding='utf-8') as f:\n        return f.read()\n# Read requirements\ndef read_requirements(filename):\n    requirements_path = os.path.join(os.path.dirname(__file__), filename)\n    with open(requirements_path, 'r', encoding='utf-8') as f:\n        return [line.strip() for line in f \n                if line.strip() and not line.startswith('#')]",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "read_requirements",
        "kind": 2,
        "importPath": "setup",
        "description": "setup",
        "peekOfCode": "def read_requirements(filename):\n    requirements_path = os.path.join(os.path.dirname(__file__), filename)\n    with open(requirements_path, 'r', encoding='utf-8') as f:\n        return [line.strip() for line in f \n                if line.strip() and not line.startswith('#')]\nsetup(\n    name=\"maht-net\",\n    version=\"1.0.0\",\n    author=\"Mohamed Nourdine\",\n    author_email=\"mohamednjikam25@hotmail.com\", ",
        "detail": "setup",
        "documentation": {}
    },
    {
        "label": "parse_args",
        "kind": 2,
        "importPath": "train",
        "description": "train",
        "peekOfCode": "def parse_args():\n    \"\"\"Parse command line arguments\"\"\"\n    parser = argparse.ArgumentParser(description=\"Train MAHT-Net for Cephalometric Landmark Detection\")\n    parser.add_argument(\n        '--config',\n        type=str,\n        default='configs/train_config.json',\n        help='Path to training configuration file'\n    )\n    parser.add_argument(",
        "detail": "train",
        "documentation": {}
    },
    {
        "label": "load_config",
        "kind": 2,
        "importPath": "train",
        "description": "train",
        "peekOfCode": "def load_config(config_path: str, args) -> dict:\n    \"\"\"Load and validate training configuration\"\"\"\n    with open(config_path, 'r') as f:\n        config = json.load(f)\n    # Override config with command line arguments\n    if args.data_dir:\n        config['data']['data_dir'] = args.data_dir\n    if args.output_dir:\n        config['experiment']['output_dir'] = args.output_dir\n    # Debug mode adjustments",
        "detail": "train",
        "documentation": {}
    },
    {
        "label": "setup_device",
        "kind": 2,
        "importPath": "train",
        "description": "train",
        "peekOfCode": "def setup_device(gpu_id: int = None) -> torch.device:\n    \"\"\"Setup compute device\"\"\"\n    if gpu_id is not None:\n        if torch.cuda.is_available():\n            device = torch.device(f'cuda:{gpu_id}')\n            torch.cuda.set_device(gpu_id)\n        else:\n            logger.warning(\"CUDA not available, falling back to CPU\")\n            device = torch.device('cpu')\n    else:",
        "detail": "train",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "train",
        "description": "train",
        "peekOfCode": "def main():\n    \"\"\"Main training function\"\"\"\n    # Parse arguments\n    args = parse_args()\n    # Load configuration\n    config = load_config(args.config, args)\n    # Setup device\n    device = setup_device(args.gpu)\n    # Set random seeds for reproducibility\n    torch.manual_seed(config['experiment']['random_seed'])",
        "detail": "train",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "train",
        "description": "train",
        "peekOfCode": "logger = logging.getLogger(__name__)\ndef parse_args():\n    \"\"\"Parse command line arguments\"\"\"\n    parser = argparse.ArgumentParser(description=\"Train MAHT-Net for Cephalometric Landmark Detection\")\n    parser.add_argument(\n        '--config',\n        type=str,\n        default='configs/train_config.json',\n        help='Path to training configuration file'\n    )",
        "detail": "train",
        "documentation": {}
    }
]