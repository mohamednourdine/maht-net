# MAHT-Net: Multi-Stage Attention-enhanced Hybrid Transformer Network
# Requirements for cephalometric landmark detection with clinical-grade precision

# Core ML Framework
torch>=2.1.0
torchvision>=0.16.0
torchaudio>=2.1.0

# Deep Learning Utilities
transformers>=4.35.0
timm>=0.9.12
einops>=0.7.0
fvcore>=0.1.5

# Computer Vision & Image Processing
opencv-python>=4.8.0
Pillow>=10.0.0
scikit-image>=0.21.0
albumentations>=1.3.1
imgaug>=0.4.0

# Medical Imaging
pydicom>=2.4.3
SimpleITK>=2.3.0
nibabel>=5.1.0

# Scientific Computing
numpy>=1.24.0
scipy>=1.11.0
pandas>=2.1.0
scikit-learn>=1.3.0

# Visualization & Monitoring
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.17.0
tensorboard>=2.14.0
wandb>=0.16.0

# Configuration & Utilities
PyYAML>=6.0
hydra-core>=1.3.0
omegaconf>=2.3.0
rich>=13.6.0
tqdm>=4.66.0

# AWS Integration
boto3>=1.29.0
awscli>=1.29.0
s3fs>=2023.9.0

# API & Web Framework
fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.4.0
requests>=2.31.0

# Database & Storage
sqlalchemy>=2.0.0
alembic>=1.12.0
redis>=5.0.0

# Testing & Quality
pytest>=7.4.0
pytest-cov>=4.1.0
black>=23.9.0
isort>=5.12.0
flake8>=6.1.0
pylint>=3.0.0
mypy>=1.6.0
pre-commit>=3.5.0

# Documentation
sphinx>=7.2.0
sphinx-rtd-theme>=1.3.0
myst-parser>=2.0.0

# Production & Deployment
gunicorn>=21.2.0
docker>=6.1.0
kubernetes>=28.1.0

# Clinical Integration
hl7apy>=1.3.4
pynetdicom>=2.0.2

# Optional GPU Support (uncomment if using CUDA)
# --extra-index-url https://download.pytorch.org/whl/cu121
# torch>=2.1.0+cu121
# torchvision>=0.16.0+cu121
# torchaudio>=2.1.0+cu121
